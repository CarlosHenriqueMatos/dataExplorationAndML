{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53b264b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-17T18:12:20.246658Z",
     "iopub.status.busy": "2024-12-17T18:12:20.246362Z",
     "iopub.status.idle": "2024-12-17T18:12:21.325296Z",
     "shell.execute_reply": "2024-12-17T18:12:21.324075Z"
    },
    "papermill": {
     "duration": 1.083786,
     "end_time": "2024-12-17T18:12:21.326855",
     "exception": false,
     "start_time": "2024-12-17T18:12:20.243069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s3e23/sample_submission.csv\n",
      "/kaggle/input/playground-series-s3e23/train.csv\n",
      "/kaggle/input/playground-series-s3e23/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ecdc39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T18:12:21.331898Z",
     "iopub.status.busy": "2024-12-17T18:12:21.331476Z",
     "iopub.status.idle": "2024-12-17T18:12:21.650959Z",
     "shell.execute_reply": "2024-12-17T18:12:21.650060Z"
    },
    "papermill": {
     "duration": 0.32391,
     "end_time": "2024-12-17T18:12:21.652681",
     "exception": false,
     "start_time": "2024-12-17T18:12:21.328771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "database = pd.read_csv('/kaggle/input/playground-series-s3e23/train.csv')\n",
    "database = database.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5753b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T18:12:21.657476Z",
     "iopub.status.busy": "2024-12-17T18:12:21.657156Z",
     "iopub.status.idle": "2024-12-17T18:12:37.486690Z",
     "shell.execute_reply": "2024-12-17T18:12:37.485627Z"
    },
    "papermill": {
     "duration": 15.834484,
     "end_time": "2024-12-17T18:12:37.488876",
     "exception": false,
     "start_time": "2024-12-17T18:12:21.654392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustando outliers na coluna: loc\n",
      "Coluna ajustada: \n",
      "Q1: 13.00, Q3: 42.00, IIQ: 29.00\n",
      "Limite Inferior: -30.50, Limite Superior: 85.50\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: v(g)\n",
      "Coluna ajustada: \n",
      "Q1: 2.00, Q3: 6.00, IIQ: 4.00\n",
      "Limite Inferior: -4.00, Limite Superior: 12.00\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: ev(g)\n",
      "Coluna ajustada: \n",
      "Q1: 1.00, Q3: 3.00, IIQ: 2.00\n",
      "Limite Inferior: -2.00, Limite Superior: 6.00\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: iv(g)\n",
      "Coluna ajustada: \n",
      "Q1: 1.00, Q3: 4.00, IIQ: 3.00\n",
      "Limite Inferior: -3.50, Limite Superior: 8.50\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: n\n",
      "Coluna ajustada: \n",
      "Q1: 25.00, Q3: 111.00, IIQ: 86.00\n",
      "Limite Inferior: -104.00, Limite Superior: 240.00\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: v\n",
      "Coluna ajustada: \n",
      "Q1: 97.67, Q3: 560.25, IIQ: 462.58\n",
      "Limite Inferior: -596.20, Limite Superior: 1254.12\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: l\n",
      "Coluna ajustada: \n",
      "Q1: 0.05, Q3: 0.15, IIQ: 0.10\n",
      "Limite Inferior: -0.10, Limite Superior: 0.30\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: d\n",
      "Coluna ajustada: \n",
      "Q1: 5.60, Q3: 18.00, IIQ: 12.40\n",
      "Limite Inferior: -13.00, Limite Superior: 36.60\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: i\n",
      "Coluna ajustada: \n",
      "Q1: 15.56, Q3: 34.34, IIQ: 18.78\n",
      "Limite Inferior: -12.61, Limite Superior: 62.51\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: e\n",
      "Coluna ajustada: \n",
      "Q1: 564.73, Q3: 10193.24, IIQ: 9628.51\n",
      "Limite Inferior: -13878.03, Limite Superior: 24636.00\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: b\n",
      "Coluna ajustada: \n",
      "Q1: 0.03, Q3: 0.19, IIQ: 0.16\n",
      "Limite Inferior: -0.21, Limite Superior: 0.43\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: t\n",
      "Coluna ajustada: \n",
      "Q1: 31.38, Q3: 565.92, IIQ: 534.54\n",
      "Limite Inferior: -770.43, Limite Superior: 1367.73\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: lOCode\n",
      "Coluna ajustada: \n",
      "Q1: 7.00, Q3: 26.00, IIQ: 19.00\n",
      "Limite Inferior: -21.50, Limite Superior: 54.50\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: lOComment\n",
      "Coluna ajustada: \n",
      "Q1: 0.00, Q3: 1.00, IIQ: 1.00\n",
      "Limite Inferior: -1.50, Limite Superior: 2.50\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: lOBlank\n",
      "Coluna ajustada: \n",
      "Q1: 1.00, Q3: 5.00, IIQ: 4.00\n",
      "Limite Inferior: -5.00, Limite Superior: 11.00\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: locCodeAndComment\n",
      "Coluna ajustada: \n",
      "Q1: 0.00, Q3: 0.00, IIQ: 0.00\n",
      "Limite Inferior: 0.00, Limite Superior: 0.00\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: uniq_Op\n",
      "Coluna ajustada: \n",
      "Q1: 8.00, Q3: 16.00, IIQ: 8.00\n",
      "Limite Inferior: -4.00, Limite Superior: 28.00\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: uniq_Opnd\n",
      "Coluna ajustada: \n",
      "Q1: 7.00, Q3: 20.00, IIQ: 13.00\n",
      "Limite Inferior: -12.50, Limite Superior: 39.50\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: total_Op\n",
      "Coluna ajustada: \n",
      "Q1: 15.00, Q3: 66.00, IIQ: 51.00\n",
      "Limite Inferior: -61.50, Limite Superior: 142.50\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: total_Opnd\n",
      "Coluna ajustada: \n",
      "Q1: 10.00, Q3: 45.00, IIQ: 35.00\n",
      "Limite Inferior: -42.50, Limite Superior: 97.50\n",
      "--------------------------------------------------\n",
      "Ajustando outliers na coluna: branchCount\n",
      "Coluna ajustada: \n",
      "Q1: 3.00, Q3: 11.00, IIQ: 8.00\n",
      "Limite Inferior: -9.00, Limite Superior: 23.00\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers foram ajustados com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/1290964845.py:37: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '54.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_capped[data_capped > upper_limit] = upper_limit\n",
      "/tmp/ipykernel_17/1290964845.py:37: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_capped[data_capped > upper_limit] = upper_limit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tqdm import tqdm\n",
    "\n",
    "def capOutliers(data: pd.Series):\n",
    "    \"\"\"\n",
    "    Cap values of a numeric series to upper and lower limits based on IQR.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): A numeric pandas Series.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The capped pandas Series.\n",
    "    \"\"\"\n",
    "    # Calcula os quartis e o intervalo interquartil (IIQ)\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Define os limites inferior e superior\n",
    "    lower_limit = q1 - 1.5 * iqr\n",
    "    upper_limit = q3 + 1.5 * iqr\n",
    "\n",
    "    # Aplica os limites para capear os valores\n",
    "    data_capped = data.copy()\n",
    "    data_capped[data_capped > upper_limit] = upper_limit\n",
    "    data_capped[data_capped < lower_limit] = lower_limit\n",
    "\n",
    "    print(f\"Coluna ajustada: \")\n",
    "    print(f\"Q1: {q1:.2f}, Q3: {q3:.2f}, IIQ: {iqr:.2f}\")\n",
    "    print(f\"Limite Inferior: {lower_limit:.2f}, Limite Superior: {upper_limit:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return data_capped\n",
    "\n",
    "def processOutliers(database: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Processa e ajusta os outliers em colunas numéricas de um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        database (pd.DataFrame): DataFrame contendo os dados.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com outliers ajustados.\n",
    "    \"\"\"\n",
    "    numeric_columns = database.select_dtypes(include=['number']).columns\n",
    "    for column in numeric_columns:\n",
    "        print(f\"Ajustando outliers na coluna: {column}\")\n",
    "        database[column] = capOutliers(database[column])\n",
    "    print(\"\\nOutliers foram ajustados com sucesso.\")\n",
    "    return database\n",
    "\n",
    "database = processOutliers(database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae18d205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T18:12:37.493864Z",
     "iopub.status.busy": "2024-12-17T18:12:37.493359Z",
     "iopub.status.idle": "2024-12-17T18:13:38.688713Z",
     "shell.execute_reply": "2024-12-17T18:13:38.687598Z"
    },
    "papermill": {
     "duration": 61.199705,
     "end_time": "2024-12-17T18:13:38.690376",
     "exception": false,
     "start_time": "2024-12-17T18:12:37.490671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando o modelo: logistic_regression\n",
      "Modelo logistic_regression - Acurácia no conjunto de validação: 0.8098\n",
      "Modelo logistic_regression salvo em logistic_regression.pkl\n",
      "Submissão salva como 'logistic_regression_submission.csv'\n",
      "\n",
      "Treinando o modelo: random_forest\n",
      "Modelo random_forest - Acurácia no conjunto de validação: 0.8093\n",
      "Modelo random_forest salvo em random_forest.pkl\n",
      "Submissão salva como 'random_forest_submission.csv'\n",
      "\n",
      "Treinando o modelo: decision_tree\n",
      "Modelo decision_tree - Acurácia no conjunto de validação: 0.7172\n",
      "Modelo decision_tree salvo em decision_tree.pkl\n",
      "Submissão salva como 'decision_tree_submission.csv'\n",
      "\n",
      "Treinando o modelo: mlp\n",
      "Epoch 1/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8096 - loss: 0.4474 - val_accuracy: 0.8133 - val_loss: 0.4333\n",
      "Epoch 2/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8090 - loss: 0.4385 - val_accuracy: 0.8136 - val_loss: 0.4334\n",
      "Epoch 3/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8142 - loss: 0.4326 - val_accuracy: 0.8139 - val_loss: 0.4315\n",
      "Epoch 4/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8152 - loss: 0.4294 - val_accuracy: 0.8133 - val_loss: 0.4306\n",
      "Epoch 5/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8139 - loss: 0.4323 - val_accuracy: 0.8128 - val_loss: 0.4307\n",
      "Epoch 6/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.4318 - val_accuracy: 0.8129 - val_loss: 0.4308\n",
      "Epoch 7/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8138 - loss: 0.4320 - val_accuracy: 0.8126 - val_loss: 0.4317\n",
      "Epoch 8/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8160 - loss: 0.4302 - val_accuracy: 0.8131 - val_loss: 0.4315\n",
      "Epoch 9/100\n",
      "\u001b[1m2545/2545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8157 - loss: 0.4281 - val_accuracy: 0.8138 - val_loss: 0.4334\n",
      "\u001b[1m637/637\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step\n",
      "Modelo mlp - Acurácia no conjunto de validação: 0.8133\n",
      "Modelo mlp salvo em mlp.pkl\n",
      "\u001b[1m2121/2121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757us/step\n",
      "Submissão salva como 'mlp_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(model, X_test, test_ids):\n",
    "    predictions = model.predict_proba(X_test)[:, 1]\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'defects': predictions\n",
    "    })\n",
    "    return submission_df\n",
    "    \n",
    "# Função para processar os outliers (ajustar conforme sua necessidade)\n",
    "def processOutliers(database):\n",
    "    # Aqui você pode aplicar a remoção de outliers com base nos limites superiores e inferiores\n",
    "    Q3 = np.percentile(database, 75)\n",
    "    Q1 = np.percentile(database, 25)\n",
    "    IIQ = Q3 - Q1\n",
    "    LS = Q3 + (1.5 * IIQ)\n",
    "    LI = Q1 - (1.5 * IIQ)\n",
    "    \n",
    "    # Substituindo os outliers pelos limites superiores/inferiores\n",
    "    database = np.where(database > LS, LS, database)\n",
    "    database = np.where(database < LI, LI, database)\n",
    "    \n",
    "    return database\n",
    "\n",
    "# Carregar e processar os dados\n",
    "def loadAndPreprocessData(file_path):\n",
    "    # Carregar os dados\n",
    "    database = pd.read_csv(file_path)\n",
    "    \n",
    "    # Processar outliers (ajustado para o dataset completo, incluindo features)\n",
    "    X = database.drop(columns=['defects'])\n",
    "    y = database['defects']\n",
    "    \n",
    "    # Processar os dados de entrada\n",
    "    X = processOutliers(X)\n",
    "    \n",
    "    # Dividir o dataset em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Escalonamento dos dados\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Modelo 1: Regressão Logística com tqdm\n",
    "def trainLogisticRegression(X_train, y_train):\n",
    "    print(\"Treinando Regressão Logística...\")\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    # Simulando barra de progresso para treinar em etapas\n",
    "    for _ in tqdm(range(1), desc=\"Treinando\"):\n",
    "        model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Modelo 3: Random Forest com tqdm\n",
    "def trainRandomForest(X_train, y_train):\n",
    "    print(\"Treinando Random Forest...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    for _ in tqdm(range(1), desc=\"Treinando\"):\n",
    "        model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Modelo 4: MLP com 256 camadas e callback de progresso\n",
    "def trainMLP(X_train, y_train, input_dim):\n",
    "    print(\"Treinando MLP com 256 camadas...\")\n",
    "    \n",
    "    # Ajuste para usar a camada de entrada corretamente\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))  # Definindo a camada de entrada\n",
    "    \n",
    "    for _ in range(3):\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Barra de progresso para o treinamento\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Avaliação de modelos\n",
    "def evaluateModel(model, X_test, y_test, isMLP=False):\n",
    "    if isMLP:\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Função para fazer as predições e salvar a submissão\n",
    "def make_predictions(model, X_test, test_ids):\n",
    "    # Gerar as predições\n",
    "    predictions = model.predict(X_test)[:, 0]  # Ou model.predict_proba(X_test)[:, 1] se o modelo retornar probabilidades\n",
    "    # Criar o DataFrame com as predições\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'defects': predictions\n",
    "    })\n",
    "    return submission_df\n",
    "\n",
    "# Função para salvar o modelo treinado\n",
    "def save_trained_model(model, model_name='trained_model.h5'):\n",
    "    # Salvar o modelo em um arquivo .h5\n",
    "    model.save(model_name)\n",
    "    print(f\"Modelo salvo como {model_name}\")\n",
    "\n",
    "# Função para carregar o modelo salvo\n",
    "def load_trained_model(model_name='trained_model.h5'):\n",
    "    # Carregar o modelo salvo\n",
    "    model = load_model(model_name)\n",
    "    print(f\"Modelo carregado: {model_name}\")\n",
    "    return model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Função para carregar e preparar os dados\n",
    "def load_and_prepare_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    X = train_data.drop(['id', 'defects'], axis=1)\n",
    "    y = train_data['defects']\n",
    "    X_test = test_data.drop(['id'], axis=1)\n",
    "    \n",
    "    return X, y, X_test, test_data['id']\n",
    "\n",
    "# Função para treinar o modelo (classificador)\n",
    "def train_model(X, y, model_type='logistic_regression'):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if model_type == 'logistic_regression':\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'decision_tree':\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_type == 'mlp':\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(X_train.shape[1],)))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    if model_type == 'mlp':\n",
    "        # Adicionando EarlyStopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), \n",
    "                  verbose=1, callbacks=[early_stopping])\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Avaliação do modelo (no conjunto de validação)\n",
    "    if model_type == 'mlp':\n",
    "        y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        y_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Modelo {model_type} - Acurácia no conjunto de validação: {accuracy:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Função para gerar predições e salvar em CSV\n",
    "def make_predictions(model, X_test, test_ids):\n",
    "    if isinstance(model, Sequential):  # MLP (Keras)\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = (predictions > 0.5).astype(\"int32\")[:, 0]\n",
    "    else:  # Modelos clássicos como LogisticRegression, RandomForest, DecisionTree\n",
    "        predictions = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'defects': predictions\n",
    "    })\n",
    "    return submission_df\n",
    "\n",
    "# Função para salvar o modelo\n",
    "def save_model(model, model_name):\n",
    "    with open(f'{model_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Modelo {model_name} salvo em {model_name}.pkl\")\n",
    "\n",
    "# Função principal\n",
    "def main():\n",
    "    train_path = '/kaggle/input/playground-series-s3e23/train.csv'\n",
    "    test_path = '/kaggle/input/playground-series-s3e23/test.csv'\n",
    "    \n",
    "    # Carregar dados\n",
    "    X, y, X_test, test_ids = load_and_prepare_data(train_path, test_path)\n",
    "    \n",
    "    # Normalizar os dados\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Treinar e fazer predições com diferentes modelos\n",
    "    models = ['logistic_regression', 'random_forest', 'decision_tree', 'mlp']\n",
    "    \n",
    "    for model_type in models:\n",
    "        print(f\"\\nTreinando o modelo: {model_type}\")\n",
    "        \n",
    "        model = train_model(X, y, model_type=model_type)\n",
    "        \n",
    "        # Salvar o modelo\n",
    "        save_model(model, model_type)\n",
    "        \n",
    "        # Gerar predições e salvar arquivo de submissão\n",
    "        submission_df = make_predictions(model, X_test, test_ids)\n",
    "        submission_df.to_csv(f'{model_type}_submission.csv', index=False)\n",
    "        print(f\"Submissão salva como '{model_type}_submission.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6622167,
     "sourceId": 60890,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 83.502218,
   "end_time": "2024-12-17T18:13:41.113344",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-17T18:12:17.611126",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
