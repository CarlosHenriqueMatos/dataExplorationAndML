{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"26uIl2XGkgcN"},"source":["\n","# Image Colorization With GANs\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfLiBjvlJeUl","outputId":"4a785dba-dd24-4673-986f-567838ad0b9e","executionInfo":{"status":"ok","timestamp":1734989506530,"user_tz":180,"elapsed":2293,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","# Parameters\n","batch_size = 32\n","img_size = 128\n","train_val_split = 0.9  # Proporção de treino e validação\n","master_dir = '/content/drive/MyDrive/Mestrado/2024_2/Topicos_especiais_IA_ThiagoPX/NormalAndMonet'\n","test_dir = '/content/drive/MyDrive/Mestrado/2024_2/Topicos_especiais_IA_ThiagoPX/testFolder'\n","\n","# Image loading and preprocessing\n","def load_and_preprocess_image(image_path):\n","    # Load RGB image\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [img_size, img_size])\n","    img = img / 255.0  # Normalize to [0, 1]\n","\n","    # Convert to grayscale\n","    gray_img = tf.image.rgb_to_grayscale(img)\n","    return gray_img, img\n","\n","# Create train/validation dataset\n","image_files = [os.path.join(master_dir, fname) for fname in os.listdir(master_dir)]\n","train_size = int(train_val_split * len(image_files))\n","train_files = image_files[:train_size]\n","val_files = image_files[train_size:]\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_files)\n","val_dataset = tf.data.Dataset.from_tensor_slices(val_files)\n","\n","# Create test dataset\n","test_files = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir)]\n","test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n","\n","# Map the preprocessing function\n","train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","val_dataset = val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","# Batch the datasets\n","train_dataset = train_dataset.batch(batch_size)\n","val_dataset = val_dataset.batch(batch_size)\n","test_dataset = test_dataset.batch(batch_size)\n","\n","# Prefetch for performance optimization\n","train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n","val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n","test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n","\n","# Print to check the datasets\n","print(f\"Train Dataset: {len(list(train_dataset))} batches\")\n","print(f\"Validation Dataset: {len(list(val_dataset))} batches\")\n","print(f\"Test Dataset: {len(list(test_dataset))} batches\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3juHPenx8KxO","executionInfo":{"status":"ok","timestamp":1734989525126,"user_tz":180,"elapsed":18597,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}},"outputId":"a3b4d32d-c45e-4626-f2d0-3f72f98efc2f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset: 29 batches\n","Validation Dataset: 4 batches\n","Test Dataset: 1 batches\n"]}]},{"cell_type":"code","metadata":{"id":"tIZEoRpB03YS","executionInfo":{"status":"ok","timestamp":1734989525126,"user_tz":180,"elapsed":3,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}}},"source":["def get_generator_model():\n","    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 1))\n","\n","    # Encoder com Dropout\n","    conv1 = tf.keras.layers.Conv2D(16, kernel_size=(5, 5), strides=1)(inputs)\n","    conv1 = tf.keras.layers.LeakyReLU()(conv1)\n","    conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1)(conv1)\n","    conv1 = tf.keras.layers.LeakyReLU()(conv1)\n","    conv1 = tf.keras.layers.Dropout(0.2)(conv1)\n","    conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1)(conv1)\n","    conv1 = tf.keras.layers.LeakyReLU()(conv1)\n","\n","    conv2 = tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides=1)(conv1)\n","    conv2 = tf.keras.layers.LeakyReLU()(conv2)\n","    conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1)(conv2)\n","    conv2 = tf.keras.layers.LeakyReLU()(conv2)\n","    conv2 = tf.keras.layers.Dropout(0.2)(conv2)\n","    conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1)(conv2)\n","    conv2 = tf.keras.layers.LeakyReLU()(conv2)\n","\n","    conv3 = tf.keras.layers.Conv2D(64, kernel_size=(5, 5), strides=1)(conv2)\n","    conv3 = tf.keras.layers.LeakyReLU()(conv3)\n","    conv3 = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1)(conv3)\n","    conv3 = tf.keras.layers.LeakyReLU()(conv3)\n","    conv3 = tf.keras.layers.Dropout(0.2)(conv3)\n","    conv3 = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1)(conv3)\n","    conv3 = tf.keras.layers.LeakyReLU()(conv3)\n","\n","    # Bottleneck\n","    bottleneck = tf.keras.layers.Conv2D(256, kernel_size=(5, 5), strides=1, activation='tanh', padding='same')(conv3)\n","\n","    # Decoder com Dropout\n","    concat_1 = tf.keras.layers.Concatenate()([bottleneck, conv3])\n","    conv_up_3 = tf.keras.layers.Conv2DTranspose(128, kernel_size=(3, 3), strides=1, activation='relu')(concat_1)\n","    conv_up_3 = tf.keras.layers.Conv2DTranspose(128, kernel_size=(3, 3), strides=1, activation='relu')(conv_up_3)\n","    conv_up_3 = tf.keras.layers.Dropout(0.2)(conv_up_3)\n","    conv_up_3 = tf.keras.layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=1, activation='relu')(conv_up_3)\n","\n","    concat_2 = tf.keras.layers.Concatenate()([conv_up_3, conv2])\n","    conv_up_2 = tf.keras.layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=1, activation='relu')(concat_2)\n","    conv_up_2 = tf.keras.layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=1, activation='relu')(conv_up_2)\n","    conv_up_2 = tf.keras.layers.Dropout(0.2)(conv_up_2)\n","    conv_up_2 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(5, 5), strides=1, activation='relu')(conv_up_2)\n","\n","    concat_3 = tf.keras.layers.Concatenate()([conv_up_2, conv1])\n","    conv_up_1 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=1, activation='relu')(concat_3)\n","    conv_up_1 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=1, activation='relu')(conv_up_1)\n","    conv_up_1 = tf.keras.layers.Conv2DTranspose(3, kernel_size=(5, 5), strides=1, activation='relu')(conv_up_1)\n","\n","    model = tf.keras.models.Model(inputs, conv_up_1)\n","    return model\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MN4QA16xSbi","executionInfo":{"status":"ok","timestamp":1734989525126,"user_tz":180,"elapsed":2,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}}},"source":["def get_discriminator_model():\n","    layers = [\n","        tf.keras.layers.Conv2D(32, kernel_size=(7, 7), strides=1, activation='relu', input_shape=(img_size, img_size, 3)),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Conv2D(32, kernel_size=(7, 7), strides=1, activation='relu'),\n","        tf.keras.layers.MaxPooling2D(),\n","        tf.keras.layers.Conv2D(64, kernel_size=(5, 5), strides=1, activation='relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Conv2D(64, kernel_size=(5, 5), strides=1, activation='relu'),\n","        tf.keras.layers.MaxPooling2D(),\n","        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1, activation='relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1, activation='relu'),\n","        tf.keras.layers.MaxPooling2D(),\n","        tf.keras.layers.Conv2D(256, kernel_size=(3, 3), strides=1, activation='relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Conv2D(256, kernel_size=(3, 3), strides=1, activation='relu'),\n","        tf.keras.layers.MaxPooling2D(),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(512, activation='relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(16, activation='relu'),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ]\n","    model = tf.keras.models.Sequential(layers)\n","    return model\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXLB6fR4fFQP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734989527482,"user_tz":180,"elapsed":2358,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}},"outputId":"63e9972a-f9e6-44b1-9957-a0b756edf889"},"source":["import tensorflow as tf\n","\n","cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n","mse = tf.keras.losses.MeanSquaredError()\n","\n","def discriminator_loss(real_output, fake_output):\n","\n","    real_labels = tf.ones_like(real_output) - tf.random.uniform(shape=real_output.shape, maxval=0.1)\n","    fake_labels = tf.zeros_like(fake_output) + tf.random.uniform(shape=fake_output.shape, maxval=0.1)\n","\n","    real_loss = cross_entropy(real_labels, real_output)\n","    fake_loss = cross_entropy(fake_labels, fake_output)\n","\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","def generator_loss(fake_output, real_y):\n","    \"\"\"\n","    Calcula a perda do gerador usando o erro médio quadrático (MSE).\n","    \"\"\"\n","    real_y = tf.cast(real_y, tf.float32)\n","    return mse(fake_output, real_y)\n","\n","learning_rate = 0.001\n","generator_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5, beta_2=0.999)\n","discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5, beta_2=0.999)\n","\n","generator = get_generator_model()\n","discriminator = get_discriminator_model()\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","metadata":{"id":"sxUEQpDmgoLa","executionInfo":{"status":"ok","timestamp":1734989527482,"user_tz":180,"elapsed":3,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}}},"source":["import tensorflow as tf\n","from tqdm import tqdm\n","\n","gen_loss_metric = tf.keras.metrics.Mean(name=\"gen_loss\")\n","disc_loss_metric = tf.keras.metrics.Mean(name=\"disc_loss\")\n","\n","early_stopping_patience = 10\n","best_gen_loss = float('inf')\n","patience_counter = 0\n","\n","@tf.function\n","def train_step(input_x, real_y):\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        generated_images = generator(input_x, training=True)\n","\n","        real_output = discriminator(real_y, training=True)\n","        generated_output = discriminator(generated_images, training=True)\n","\n","        gen_loss = generator_loss(generated_images, real_y)\n","        disc_loss = discriminator_loss(real_output, generated_output)\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","\n","    gen_loss_metric.update_state(gen_loss)\n","    disc_loss_metric.update_state(disc_loss)\n","\n","def train(dataset, epochs):\n","    \"\"\"\n","    Loop principal de treinamento.\n","    \"\"\"\n","    global best_gen_loss, patience_counter\n","\n","    for epoch in range(epochs):\n","        gen_loss_metric.reset_state()\n","        disc_loss_metric.reset_state()\n","\n","        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n","        progress_bar = tqdm(dataset, desc=\"Training\", leave=True)\n","\n","        for input_x, real_y in progress_bar:\n","            train_step(input_x, real_y)\n","            progress_bar.set_postfix({\n","                \"Generator Loss\": f\"{gen_loss_metric.result():.4f}\",\n","                \"Discriminator Loss\": f\"{disc_loss_metric.result():.4f}\"\n","            })\n","\n","        print(f\"Generator Loss: {gen_loss_metric.result():.4f}, Discriminator Loss: {disc_loss_metric.result():.4f}\")\n","\n","        current_gen_loss = gen_loss_metric.result()\n","        if current_gen_loss < best_gen_loss:\n","            best_gen_loss = current_gen_loss\n","            patience_counter = 0\n","            print(\"Validation improvement. Saving best model...\\n\")\n","            generator.save_weights(\"/content/drive/MyDrive/Mestrado/2024_2/Topicos_especiais_IA_ThiagoPX/best_generator.weights.h5\")\n","            discriminator.save_weights(\"/content/drive/MyDrive/Mestrado/2024_2/Topicos_especiais_IA_ThiagoPX/best_discriminator.weights.h5\")\n","        else:\n","            patience_counter += 1\n","            print(f\"No improvement. Early stopping patience: {patience_counter}/{early_stopping_patience}\")\n","\n","\n","        if patience_counter >= early_stopping_patience:\n","            print(\"Early stopping triggered. Stopping training.\")\n","            break\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train(dataset=train_dataset, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eftrBW0tyjyt","executionInfo":{"status":"error","timestamp":1734989845443,"user_tz":180,"elapsed":317963,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}},"outputId":"bdeb56bb-b9a6-4b74-dacd-1d5a8fb0fab7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 29/29 [01:11<00:00,  2.48s/it, Generator Loss=0.1043, Discriminator Loss=1.4481]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Loss: 0.1043, Discriminator Loss: 1.4481\n","Validation improvement. Saving best model...\n","\n","\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 29/29 [00:40<00:00,  1.41s/it, Generator Loss=0.0230, Discriminator Loss=4.0285]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Loss: 0.0230, Discriminator Loss: 4.0285\n","Validation improvement. Saving best model...\n","\n","\n","Epoch 3/100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 29/29 [00:40<00:00,  1.41s/it, Generator Loss=0.0176, Discriminator Loss=1.3863]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Loss: 0.0176, Discriminator Loss: 1.3863\n","Validation improvement. Saving best model...\n","\n","\n","Epoch 4/100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 29/29 [00:40<00:00,  1.41s/it, Generator Loss=0.0149, Discriminator Loss=1.3864]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Loss: 0.0149, Discriminator Loss: 1.3864\n","Validation improvement. Saving best model...\n","\n","\n","Epoch 5/100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 29/29 [00:40<00:00,  1.41s/it, Generator Loss=0.0145, Discriminator Loss=1.3863]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Loss: 0.0145, Discriminator Loss: 1.3863\n","Validation improvement. Saving best model...\n","\n","\n","Epoch 6/100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 29/29 [00:40<00:00,  1.41s/it, Generator Loss=0.0139, Discriminator Loss=1.3856]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Loss: 0.0139, Discriminator Loss: 1.3856\n","Validation improvement. Saving best model...\n","\n","\n","Epoch 7/100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 29/29 [00:27<00:00,  1.05it/s, Generator Loss=0.0164, Discriminator Loss=1.4311]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Loss: 0.0164, Discriminator Loss: 1.4311\n","No improvement. Early stopping patience: 1/10\n","\n","Epoch 8/100\n"]},{"output_type":"stream","name":"stderr","text":["Training:  17%|█▋        | 5/29 [00:05<00:28,  1.18s/it, Generator Loss=0.1468, Discriminator Loss=1.3861]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-05ad6631da31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-91d38e2cb413>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             progress_bar.set_postfix({\n\u001b[1;32m     48\u001b[0m                 \u001b[0;34m\"Generator Loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{gen_loss_metric.result():.4f}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ynE-Hp6lWeZT"},"source":["\n","## **4. Results**\n","\n","We plotted the input, output and the original images respectively, from a part of the dataset to find out the results.\n"]},{"cell_type":"code","metadata":{"id":"NmqceMH9FTnd","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17SNG4KEJ7O4gdMAzOvyB7h65uSMBg430"},"executionInfo":{"status":"error","timestamp":1734989892541,"user_tz":180,"elapsed":42431,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}},"outputId":"67568dea-420b-4ec2-8f73-fadeb8df917e"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from PIL import Image\n","\n","def display_results(generator, test_dataset, img_size=256, output_size=(1024, 1024), weights_path=\"/content/drive/MyDrive/Mestrado/2024_2/Topicos_especiais_IA_ThiagoPX/best_generator.weights.h5\"):\n","    try:\n","        generator.load_weights(weights_path)\n","        print(f\"Pesos carregados com sucesso de: {weights_path}\")\n","    except Exception as e:\n","        print(f\"Erro ao carregar pesos: {e}\")\n","        return\n","\n","    # Iterate through the batches in the test dataset\n","    for batch_x, batch_y in test_dataset:\n","        y_pred = generator(batch_x).numpy() # Pass a batch of images to the generator\n","\n","        # Iterate through images in the current batch\n","        for i, (input_img, target_img, output_img) in enumerate(zip(batch_x, batch_y, y_pred)):\n","            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","            # Convert input_img to NumPy array before reshaping\n","            input_img_np = input_img.numpy()\n","            input_resized = Image.fromarray(input_img_np.reshape((img_size, img_size)) * 255).resize(output_size)\n","            axes[0].imshow(input_resized, cmap='gray')\n","            axes[0].set_title(\"Imagem Cinza\", fontsize=12)\n","            axes[0].axis(\"off\")\n","\n","            # Convert target_img to NumPy array before using astype\n","            target_img_np = target_img.numpy()\n","            target_resized = Image.fromarray((target_img_np * 255).astype('uint8')).resize(output_size)\n","            axes[1].imshow(target_resized)\n","            axes[1].set_title(\"Saída Objetivo\", fontsize=12)\n","            axes[1].axis(\"off\")\n","\n","            output_resized = Image.fromarray((output_img * 255).astype('uint8')).resize(output_size)\n","            axes[2].imshow(output_resized)\n","            axes[2].set_title(\"Imagem Colorida NN\", fontsize=12)\n","            axes[2].axis(\"off\")\n","\n","            plt.tight_layout()\n","            plt.show()\n","\n","display_results(generator, test_dataset, img_size=img_size, output_size=(1024, 1024), weights_path=\"/content/drive/MyDrive/Mestrado/2024_2/Topicos_especiais_IA_ThiagoPX/best_generator.weights.h5\")"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"mtyxxoeCndGx","executionInfo":{"status":"aborted","timestamp":1734989845443,"user_tz":180,"elapsed":5,"user":{"displayName":"carlos matos","userId":"02219067111046996044"}}},"execution_count":null,"outputs":[]}]}