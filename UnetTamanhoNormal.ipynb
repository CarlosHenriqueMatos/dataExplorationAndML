{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosHenriqueMatos/neuralNetworksForCompetitions/blob/main/UnetTamanhoNormal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0YzZWGz-bpM",
        "outputId": "06fdba49-4a14-477c-e103-1f138e7eaffd"
      },
      "id": "l0YzZWGz-bpM",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "kWhb50dzHzX-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWhb50dzHzX-",
        "outputId": "2bce1d49-0b15-40a9-cb3c-6a84adac5009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "xbhxakPsHkQl",
      "metadata": {
        "id": "xbhxakPsHkQl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fa62163b",
      "metadata": {
        "id": "fa62163b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm  # Para uma barra de progresso\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "#!pip install keras-adamw\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# Don't Show Warning Messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d5cd8454",
      "metadata": {
        "id": "d5cd8454"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        "IMG_CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "B-t06Yu1zeDW",
      "metadata": {
        "id": "B-t06Yu1zeDW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a19d1af1",
      "metadata": {
        "id": "a19d1af1"
      },
      "outputs": [],
      "source": [
        "# get a list of files in each folder\n",
        "\n",
        "img_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/image/')\n",
        "mask_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/label/')\n",
        "\n",
        "# create a dataframe\n",
        "train_df_images = pd.DataFrame(img_list, columns=['image_id'])\n",
        "train_df_mask = pd.DataFrame(mask_list, columns=['image_id'])\n",
        "\n",
        "# get a list of files in each folder\n",
        "\n",
        "validation_img_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Validation/images/')\n",
        "validation_mask_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Validation/masks/')\n",
        "\n",
        "# create a dataframe\n",
        "test_df_images = pd.DataFrame(validation_img_list, columns=['image_id'])\n",
        "test_df_mask = pd.DataFrame(validation_mask_list, columns=['image_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f6cde629",
      "metadata": {
        "id": "f6cde629"
      },
      "outputs": [],
      "source": [
        "# Get lists of images and their masks.\n",
        "train_image_list = list(train_df_images['image_id'])\n",
        "train_mask_list = list(train_df_mask['image_id'])\n",
        "test_image_list = list(test_df_images['image_id'])\n",
        "test_mask_list = list(test_df_mask['image_id'])\n",
        "# Create empty arrays\n",
        "\n",
        "X_train = np.zeros((len(train_image_list), IMG_HEIGHT, IMG_WIDTH,3), dtype=np.float32)#You can use float16 or 32, enhance the precision\n",
        "Y_train = np.zeros((len(train_mask_list), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
        "X_teste = np.zeros((len(test_image_list), IMG_HEIGHT, IMG_WIDTH,3), dtype=np.float32)\n",
        "Y_teste = np.zeros((len(test_mask_list), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = len(train_image_list)\n",
        "img_height, img_width, num_channels = 512, 512, 3\n",
        "\n",
        "# Pré-aloque o array\n",
        "X_train = np.zeros((num_images, img_height, img_width, num_channels), dtype=np.float32)\n",
        "\n",
        "for i, img_id in tqdm(enumerate(train_image_list)):\n",
        "    path_mask = '/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/image/' + img_id\n",
        "    image = cv2.imread(path_mask, 3)  # Usa a flag correta\n",
        "    X_train[i] = image  # Adiciona diretamente ao array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjTk_rOW_yvb",
        "outputId": "acac6e09-f00f-4792-f660-02feed436d38"
      },
      "id": "pjTk_rOW_yvb",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "499it [00:18, 27.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = len(train_image_list)\n",
        "img_height, img_width = 512, 512\n",
        "\n",
        "# Pré-aloque um array para as máscaras\n",
        "Y_train = np.zeros((num_images, img_height, img_width), dtype=np.uint8)\n",
        "\n",
        "for i, img_id in tqdm(enumerate(train_image_list)):\n",
        "    path_mask = '/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/label/' + img_id\n",
        "    image = cv2.imread(path_mask, 0)  # Ler como escala de cinza\n",
        "    Y_train[i] = image  # Adicionar diretamente ao array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oskt86FAdbq",
        "outputId": "69652a90-aee5-4ec7-c351-ec04f94396e9"
      },
      "id": "5oskt86FAdbq",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "499it [00:03, 138.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c73bf5b3",
      "metadata": {
        "id": "c73bf5b3"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Lambda\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "x24USHOjBPUU",
      "metadata": {
        "id": "x24USHOjBPUU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plota_grafico(historico):\n",
        "    # figure(figsize = (8, 6))\n",
        "    ###################### losss\n",
        "    plt.plot(historico.history['loss'])\n",
        "    plt.plot(historico.history['val_loss'])\n",
        "    plt.title('LOSS')\n",
        "    plt.ylim(ymin = 0,ymax = 1)\n",
        "\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc ='upper left')\n",
        "\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    ###################### acuracia\n",
        "\n",
        "    plt.plot(historico.history['f1_score'])\n",
        "    plt.plot(historico.history['val_f1_score'])\n",
        "    plt.title('F1 Score')\n",
        "    plt.ylim(ymin = 0,ymax = 1)\n",
        "\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc ='upper left')\n",
        "\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFvOxA8hDqIC",
        "outputId": "6c026386-2c80-4dc6-b03c-8ec7dd1416db"
      },
      "id": "gFvOxA8hDqIC",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "VOaHajJvEKsT",
      "metadata": {
        "id": "VOaHajJvEKsT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy, Metric\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "XZ1fmI7bD22n",
      "metadata": {
        "id": "XZ1fmI7bD22n"
      },
      "outputs": [],
      "source": [
        "class F1Score(Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        f1_score = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "        return f1_score\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_state()\n",
        "        self.recall.reset_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "qa5zc_oGFWN3",
      "metadata": {
        "id": "qa5zc_oGFWN3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_validate\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Importando os módulos de cálculo de métricas\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train), type(Y_train))\n",
        "print(X_train.shape, Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS8bMCMfHKe-",
        "outputId": "b6c8315b-8ac2-4fe8-ebc6-6c313e7bb406"
      },
      "id": "KS8bMCMfHKe-",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(499, 512, 512, 3) (499, 512, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "N_9ahB8Ch3xE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N_9ahB8Ch3xE",
        "outputId": "32a5bf22-bce8-488f-9c64-7299e5466d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5934 - loss: 1.2506\n",
            "Epoch 2/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 522ms/step - accuracy: 0.8655 - loss: 0.3631\n",
            "Epoch 3/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 548ms/step - accuracy: 0.8919 - loss: 0.2967\n",
            "[0.6829345226287842, 0.869829535484314, 0.8990685939788818]\n",
            "Dados Gravados\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4s/step\n",
            "Epoch 1/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 888ms/step - accuracy: 0.7106 - loss: 1.6142\n",
            "Epoch 2/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 554ms/step - accuracy: 0.9214 - loss: 0.2372\n",
            "Epoch 3/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 565ms/step - accuracy: 0.9279 - loss: 0.2144\n",
            "[0.8195514678955078, 0.9209003448486328, 0.9312499165534973]\n",
            "Dados Gravados\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step\n",
            "Epoch 1/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 779ms/step - accuracy: 0.6050 - loss: 0.7248\n",
            "Epoch 2/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 547ms/step - accuracy: 0.9046 - loss: 0.2798\n",
            "Epoch 3/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 544ms/step - accuracy: 0.9133 - loss: 0.2449\n",
            "[0.739017903804779, 0.8990497589111328, 0.914842426776886]\n",
            "Dados Gravados\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bc83af49a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 238ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bc83af49a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step\n",
            "Epoch 1/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 855ms/step - accuracy: 0.7243 - loss: 0.7020\n",
            "Epoch 2/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 551ms/step - accuracy: 0.8586 - loss: 0.3728\n",
            "Epoch 3/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 560ms/step - accuracy: 0.8974 - loss: 0.2997\n",
            "[0.807009220123291, 0.8756304383277893, 0.9036256670951843]\n",
            "Dados Gravados\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 426ms/step\n",
            "Epoch 1/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 528ms/step - accuracy: 0.6573 - loss: 0.9648\n",
            "Epoch 2/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 547ms/step - accuracy: 0.8848 - loss: 0.3197\n",
            "Epoch 3/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 551ms/step - accuracy: 0.9184 - loss: 0.2323\n",
            "[0.7587054371833801, 0.8968371748924255, 0.9229679703712463]\n",
            "Dados Gravados\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n",
            "Epoch 1/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 880ms/step - accuracy: 0.7140 - loss: 1.7660\n",
            "Epoch 2/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 545ms/step - accuracy: 0.9040 - loss: 0.2803\n",
            "Epoch 3/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 557ms/step - accuracy: 0.9259 - loss: 0.2202\n",
            "[0.8171727061271667, 0.9114456176757812, 0.9238295555114746]\n",
            "Dados Gravados\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 353ms/step\n",
            "Epoch 1/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 832ms/step - accuracy: 0.6486 - loss: 0.8839\n",
            "Epoch 2/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 542ms/step - accuracy: 0.8949 - loss: 0.3024\n",
            "Epoch 3/3\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 540ms/step - accuracy: 0.9153 - loss: 0.2428\n",
            "[0.7519353628158569, 0.8999733328819275, 0.9109535217285156]\n",
            "Dados Gravados\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354ms/step\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-843734827c39>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;31m#cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Use 5-fold cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;31m# Fit the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-843734827c39>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m         )'''\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "import tensorflow as tf\n",
        "\n",
        "class KerasEstimator(BaseEstimator):\n",
        "    instance_counter = 0\n",
        "    def __init__(self, optimizer='adam', learning_rate=0.001, ema_momentum=0.9, kernel_initializer='he_normal'):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ema_momentum = ema_momentum\n",
        "        self.optimizer = optimizer\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        KerasEstimator.instance_counter += 1  # Initialize the counter\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = self.create_model()\n",
        "\n",
        "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='accuracy',  # Monitor the f1_score on the validation set\n",
        "            patience=10,\n",
        "            verbose=1,\n",
        "            restore_best_weights=False\n",
        "        )\n",
        "\n",
        "        '''checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=\"/content/drive/MyDrive/Mestrado/2024_2/Qualification/amazonModels/carlos.h5\",\n",
        "            monitor='accuracy',  # Monitor the f1_score on the validation set\n",
        "            verbose=1,\n",
        "            save_best_only=True,\n",
        "            mode='max'\n",
        "        )'''\n",
        "\n",
        "        history = self.model.fit(X, y, batch_size=16, epochs=3, verbose=1,callbacks=[early_stopper])\n",
        "\n",
        "        print(history.history['accuracy'])\n",
        "        with open(\"/content/drive/MyDrive/Mestrado/2024_2/Qualification/amazonModels/treinos1e2.txt\", \"a\") as checkpoint_file:\n",
        "          checkpoint_file.write(\"Accuracy History: \" + str(history.history['accuracy']) + \"\\n\")\n",
        "\n",
        "        print(\"Dados Gravados\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def create_model(self):\n",
        "        #print(self.ema_momentum,self.learning_rate,self.kernel_initializer,self.optimizer)\n",
        "        inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "        s = tf.keras.layers.Lambda(lambda x: x / 65.536) (inputs)\n",
        "\n",
        "        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (s)\n",
        "        c1 = tf.keras.layers.Dropout(0.1) (c1)\n",
        "        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c1)\n",
        "        p1 = tf.keras.layers.MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "        c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p1)\n",
        "        c2 = tf.keras.layers.Dropout(0.1) (c2)\n",
        "        c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c2)\n",
        "        p2 = tf.keras.layers.MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "        c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p2)\n",
        "        c3 = tf.keras.layers.Dropout(0.2) (c3)\n",
        "        c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c3)\n",
        "        p3 = tf.keras.layers.MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "        c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p3)\n",
        "        c4 = tf.keras.layers.Dropout(0.2) (c4)\n",
        "        c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c4)\n",
        "        p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "        c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p4)\n",
        "        c5 = tf.keras.layers.Dropout(0.3) (c5)\n",
        "        c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c5)\n",
        "\n",
        "        u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "        u6 = tf.keras.layers.Concatenate()([u6, c4])  # Fix the Concatenate usage\n",
        "        c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u6)\n",
        "        c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "        c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c6)\n",
        "\n",
        "        u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "        u7 = tf.keras.layers.Concatenate()([u7, c3])  # Fix the Concatenate usage\n",
        "        c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u7)\n",
        "        c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "        c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c7)\n",
        "\n",
        "        u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "        u8 = tf.keras.layers.Concatenate()([u8, c2])  # Fix the Concatenate usage\n",
        "        c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u8)\n",
        "        c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "        c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c8)\n",
        "\n",
        "\n",
        "        u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "        u9 = tf.keras.layers.Concatenate(axis=3)([u9, c1])  # Fix the Concatenate usage\n",
        "        c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u9)\n",
        "        c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "        c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c9)\n",
        "\n",
        "        outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "        model = Model(inputs=[inputs], outputs=[outputs])  # Your model architecture here\n",
        "        model.compile(optimizer=self.get_optimizer(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def get_optimizer(self):\n",
        "        if self.optimizer == 'adam':\n",
        "            return tf.keras.optimizers.Adam(learning_rate=self.learning_rate, ema_momentum=self.ema_momentum)\n",
        "        elif self.optimizer == 'nadam':\n",
        "            return tf.keras.optimizers.Nadam(learning_rate=self.learning_rate, ema_momentum=self.ema_momentum)\n",
        "        elif self.optimizer == 'adamw':\n",
        "            # Implement AdamW optimizer (adjust parameters as needed)\n",
        "            return tf.keras.optimizers.AdamW(learning_rate=self.learning_rate, ema_momentum=self.ema_momentum)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown optimizer: {}\".format(self.optimizer))\n",
        "\n",
        "# Define hyperparameters for grid search\n",
        "parameters = {\n",
        "    'optimizer':['adam'], #['adam','nadam','adamw'],\n",
        "    'learning_rate': [0.002,0.003,0.004],\n",
        "    'ema_momentum': [0.975],\n",
        "    'kernel_initializer': ['he_normal']\n",
        "}\n",
        "\n",
        "# Create the wrapped KerasEstimator\n",
        "#cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Use 5-fold cross-validation\n",
        "clf = GridSearchCV(estimator = KerasEstimator(), param_grid=parameters,scoring = 'f1',cv=5)\n",
        "history = clf.fit(X_train, Y_train)\n",
        "# Fit the grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yYQJYpJ_JEe7",
      "metadata": {
        "id": "yYQJYpJ_JEe7"
      },
      "outputs": [],
      "source": [
        "# Acesse os melhores parâmetros encontrados no grid_result\n",
        "best_params = grid_result.best_params_\n",
        "best_score = grid_result.best_score_\n",
        "\n",
        "print(\"Melhores parâmetros encontrados: \", best_params)\n",
        "print(\"Melhor precisão encontrada: \", best_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B9n3Z2DqBRyv",
      "metadata": {
        "id": "B9n3Z2DqBRyv"
      },
      "outputs": [],
      "source": [
        "modelo = 0\n",
        "model = unet()\n",
        "for train, test in cv.split(X_train,Y_train):\n",
        "    modelo=modelo+1\n",
        "    print(modelo)\n",
        "    fold_no = 1\n",
        "    acc_per_fold = []\n",
        "    filepath = \"/content/drive/MyDrive/AMAZON/TesteUnet/Unet_Adam_1e-3_10P_he_0.90_/Unet_Adam_1e-3_10P_he_0.90_\"+str(modelo)+\".h5\"\n",
        "\n",
        "    earlystopper = EarlyStopping(patience=10, verbose=1)\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1,\n",
        "                                  save_best_only=True, mode='max')\n",
        "\n",
        "    callbacks_list = [earlystopper,checkpoint]\n",
        "\n",
        "    X = X_train[train]\n",
        "    Y = Y_train[train]\n",
        "\n",
        "    Xt = X_train[test]\n",
        "    Yt = Y_train[test]\n",
        "\n",
        "    model = unet()\n",
        "    print(\"Modelo\")\n",
        "    history=0\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3,ema_momentum=0.9),\n",
        "                  metrics=[BinaryAccuracy(), F1Score()])\n",
        "\n",
        "    history = model.fit(X, Y, batch_size=8,validation_data=(Xt, Yt), epochs = 1000,\n",
        "                    callbacks=callbacks_list,shuffle=False)\n",
        "\n",
        "    plota_grafico(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nP9daxUOlYOX",
      "metadata": {
        "id": "nP9daxUOlYOX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d58afe",
      "metadata": {
        "id": "b3d58afe",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "dir = \"/content/drive/MyDrive/AMAZON/TestesIsolados/\"\n",
        "diretorio = os.listdir(dir)\n",
        "model = unet()\n",
        "todasMatrizes=[]\n",
        "print(diretorio)\n",
        "for i in range(len(diretorio)):\n",
        "  model.load_weights(dir+diretorio[i])\n",
        "  matrizes=[]\n",
        "  matrizes2=[[0,0],[0,0]]\n",
        "  amostras = 45\n",
        "  index=0\n",
        "  for _ in range(amostras):\n",
        "\n",
        "      img = cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/image/'+test_image_list[index],3)\n",
        "      img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
        "      img = img[np.newaxis, :, :, : ]\n",
        "\n",
        "      predicted_img = model.predict(img)\n",
        "      cv2.imwrite('/content/drive/MyDrive/AMAZON/Dataset/Test/'+test_image_list[index], predicted_img)\n",
        "\n",
        "      #plt.figure(figsize=(12, 12))\n",
        "      #image = cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/image/'+test_image_list[index], 2)\n",
        "      #image=image*255\n",
        "      #plt.subplot(1, 3, 1)\n",
        "      #plt.imshow(np.squeeze(image))\n",
        "      #plt.axis('off')\n",
        "      #plt.title('Original Image')\n",
        "\n",
        "      #plt.subplot(1, 3, 2)\n",
        "      #plt.imshow(np.squeeze(cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/mask/'+test_image_list[index],0)))\n",
        "      #plt.axis('off')\n",
        "      #plt.title('Original Mask')\n",
        "      list_arr = cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/mask/'+test_image_list[index],0).tolist()\n",
        "\n",
        "      #print(list_arr[0])\n",
        "\n",
        "\n",
        "      #plt.subplot(1, 3, 3)\n",
        "      #plt.imshow(np.squeeze(predicted_img) >= 0.5 )\n",
        "      #plt.title('Prediction')\n",
        "      #plt.axis('off')\n",
        "      predicted_img=(np.squeeze(predicted_img)>=0.5)\n",
        "\n",
        "\n",
        "      # assuming the array is named 'arr'\n",
        "      predicted_img = predicted_img.astype(np.int64)\n",
        "      list_arr2 = predicted_img.tolist()\n",
        "      #print(list_arr2[0])\n",
        "      for i in range(len(list_arr)):\n",
        "        cm = confusion_matrix(list_arr[i],list_arr2[i])\n",
        "        if cm.shape == (2, 2):\n",
        "          matrizes2[0][0]+=cm[0][0]\n",
        "          matrizes2[0][1]+=cm[0][1]\n",
        "          matrizes2[1][0]+=cm[1][0]\n",
        "          matrizes2[1][1]+=cm[1][1]\n",
        "          teste=np.cumsum(matrizes2)\n",
        "      #print(teste[3])\n",
        "      print(matrizes2[0]/teste[3],'\\n',matrizes2[1]/teste[3])\n",
        "      matrizes2=[[0,0],[0,0]]\n",
        "      matrizes.append(matrizes2)\n",
        "      plt.show()\n",
        "      index += 1\n",
        "      #print(index)\n",
        "      print(index)\n",
        "  todasMatrizes.append(matrizes)\n",
        "  print(todasMatrizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "877e3c69",
      "metadata": {
        "id": "877e3c69"
      },
      "outputs": [],
      "source": [
        "sum_confusion_matrix = np.zeros_like(matrizes[0])\n",
        "\n",
        "# iterate over all matrices and add them to the sum matrix\n",
        "for matrizes in todasMatrizes:\n",
        "  for matrix in matrizes:\n",
        "      sum_confusion_matrix += matrix\n",
        "val = sum_confusion_matrix[0][0]+sum_confusion_matrix[0][1]\n",
        "val1 = sum_confusion_matrix[1][0]+sum_confusion_matrix[1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qqVVXGzpg_T-",
      "metadata": {
        "id": "qqVVXGzpg_T-"
      },
      "outputs": [],
      "source": [
        "TP=sum_confusion_matrix[0][0]\n",
        "FP=sum_confusion_matrix[0][1]\n",
        "FN=sum_confusion_matrix[1][0]\n",
        "TN=sum_confusion_matrix[1][1]\n",
        "print(TP,FP,FN,TN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fV5xzItphC2l",
      "metadata": {
        "id": "fV5xzItphC2l"
      },
      "outputs": [],
      "source": [
        "precisao = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "F1_Score = 2 * (precisao * recall) / (precisao + recall)\n",
        "acuracia = (TP+TN) / (TN+TP+FP+FN)\n",
        "iou = TP / (TP + FP + FN)\n",
        "print(\"Precisão: \",precisao,\"\\nRecall: \",recall,\"\\nF1_Score: \",F1_Score,\"\\nAcuracia: \",acuracia,\"\\nIoU: \",iou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SpLjH0INhH2E",
      "metadata": {
        "id": "SpLjH0INhH2E"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "matriz213 =[[TP/(TP + FP),FP/(TP + FP)],[FN/(FN+TN),TN/(FN+TN)]]\n",
        "sns.heatmap(matriz213, annot=True,fmt=\".3f\", annot_kws={\"size\":12}, cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wZ1mjyqd62CT",
      "metadata": {
        "id": "wZ1mjyqd62CT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}