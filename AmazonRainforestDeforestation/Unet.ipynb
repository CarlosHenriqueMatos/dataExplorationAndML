{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0YzZWGz-bpM",
        "outputId": "8da0d8c7-d90a-4428-dad4-ac2227f4cd10"
      },
      "id": "l0YzZWGz-bpM",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "kWhb50dzHzX-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWhb50dzHzX-",
        "outputId": "144f96c5-916c-4ae6-99c9-bff232fc2bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "xbhxakPsHkQl",
      "metadata": {
        "id": "xbhxakPsHkQl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fa62163b",
      "metadata": {
        "id": "fa62163b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "#!pip install keras-adamw\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# Don't Show Warning Messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d5cd8454",
      "metadata": {
        "id": "d5cd8454"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        "IMG_CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "B-t06Yu1zeDW",
      "metadata": {
        "id": "B-t06Yu1zeDW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a19d1af1",
      "metadata": {
        "id": "a19d1af1"
      },
      "outputs": [],
      "source": [
        "# get a list of files in each folder\n",
        "\n",
        "img_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/image/')\n",
        "mask_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/label/')\n",
        "\n",
        "# create a dataframe\n",
        "train_df_images = pd.DataFrame(img_list, columns=['image_id'])\n",
        "train_df_mask = pd.DataFrame(mask_list, columns=['image_id'])\n",
        "\n",
        "# get a list of files in each folder\n",
        "\n",
        "validation_img_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Validation/images/')\n",
        "validation_mask_list = os.listdir('/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Validation/masks/')\n",
        "\n",
        "# create a dataframe\n",
        "test_df_images = pd.DataFrame(validation_img_list, columns=['image_id'])\n",
        "test_df_mask = pd.DataFrame(validation_mask_list, columns=['image_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f6cde629",
      "metadata": {
        "id": "f6cde629"
      },
      "outputs": [],
      "source": [
        "# Get lists of images and their masks.\n",
        "train_image_list = list(train_df_images['image_id'])\n",
        "train_mask_list = list(train_df_mask['image_id'])\n",
        "test_image_list = list(test_df_images['image_id'])\n",
        "test_mask_list = list(test_df_mask['image_id'])\n",
        "# Create empty arrays\n",
        "\n",
        "X_train = np.zeros((len(train_image_list), IMG_HEIGHT, IMG_WIDTH,3), dtype=np.float16)#You can use float16 or 32, enhance the precision\n",
        "Y_train = np.zeros((len(train_mask_list), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
        "X_teste = np.zeros((len(test_image_list), IMG_HEIGHT, IMG_WIDTH,3), dtype=np.float16)\n",
        "Y_teste = np.zeros((len(test_mask_list), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7c0800dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c0800dc",
        "outputId": "53a9f76b-7019-4fcb-d18c-623cb68f8651",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(499, 512, 512, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "for i, img_id in enumerate(train_image_list):\n",
        "\n",
        "    path_mask = '/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/image/' + img_id\n",
        "    # read the image using skimage\n",
        "    image = cv2.imread(path_mask,IMG_CHANNELS)\n",
        "    # resize the image\n",
        "    #image = resize(image, (IMG_HEIGHT, IMG_WIDTH,3), mode='constant', preserve_range=True)\n",
        "\n",
        "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "    #image = np.expand_dims(image, axis=0)\n",
        "    # insert the image into X_train\n",
        "    X_train[i] = image\n",
        "    print(i)\n",
        "X_train.shape\n",
        "\n",
        "#verificar as proporções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f596bf24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f596bf24",
        "outputId": "43305ff6-5b09-48f5-8a88-fd6aa46f32f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(499, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Y_train\n",
        "\n",
        "\n",
        "for i, mask_id in enumerate(train_image_list):\n",
        "\n",
        "    path_mask = '/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Training/label/' + mask_id\n",
        "\n",
        "    # read the image using skimage\n",
        "    mask = cv2.imread(path_mask,0)\n",
        "    print(i)\n",
        "    # resize the image\n",
        "    #mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "\n",
        "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "    #mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "    # insert the image into Y_Train\n",
        "    Y_train[i] = mask\n",
        "\n",
        "Y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bDiINQwHr4L1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDiINQwHr4L1",
        "outputId": "bbf1d5dc-b1df-415a-b7f4-33dc6f20ddcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 512, 512, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "for i, img_id in enumerate(test_image_list):\n",
        "    #print(img_id)\n",
        "    path_mask = '/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Validation/images/' + img_id\n",
        "    # read the image using skimage\n",
        "    image = cv2.imread(path_mask,3)\n",
        "    print(i)\n",
        "    # resize the image\n",
        "    #image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "\n",
        "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "    #image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # insert the image into X_train\n",
        "    X_teste[i] = image\n",
        "\n",
        "X_teste.shape\n",
        "\n",
        "#verificar as proporções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "odv6FpbJe1SR",
      "metadata": {
        "id": "odv6FpbJe1SR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d30b23-7cfe-4b74-9724-c9383e99a141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "for i, img_id in enumerate(test_image_list):\n",
        "    #print(img_id)\n",
        "    path_mask = '/content/drive/MyDrive/IFES_2023/AMAZON/Backup_Dataset/Validation/masks/' + img_id\n",
        "    # read the image using skimage\n",
        "    mask = cv2.imread(path_mask,0)\n",
        "    print(i)\n",
        "    # resize the image\n",
        "    #mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "\n",
        "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "    #mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "    # insert the image into X_train\n",
        "    Y_teste[i] = mask\n",
        "\n",
        "Y_teste.shape\n",
        "\n",
        "#verificar as proporções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c73bf5b3",
      "metadata": {
        "id": "c73bf5b3"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Lambda\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "x24USHOjBPUU",
      "metadata": {
        "id": "x24USHOjBPUU"
      },
      "outputs": [],
      "source": [
        "### ESTA PARTE FOI PEGA DO CODIGO DA EDUARDA ####\n",
        "def plota_grafico(historico):\n",
        "    # figure(figsize = (8, 6))\n",
        "    ###################### losss\n",
        "    plt.plot(historico.history['loss'])\n",
        "    plt.plot(historico.history['val_loss'])\n",
        "    plt.title('LOSS')\n",
        "    plt.ylim(ymin = 0,ymax = 1)\n",
        "\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc ='upper left')\n",
        "\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    ###################### acuracia\n",
        "\n",
        "    plt.plot(historico.history['f1_score'])\n",
        "    plt.plot(historico.history['val_f1_score'])\n",
        "    plt.title('F1 Score')\n",
        "    plt.ylim(ymin = 0,ymax = 1)\n",
        "\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc ='upper left')\n",
        "\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFvOxA8hDqIC",
        "outputId": "36bae93a-11ea-42e8-935c-f345b9fc2766"
      },
      "id": "gFvOxA8hDqIC",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "VOaHajJvEKsT",
      "metadata": {
        "id": "VOaHajJvEKsT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy, Metric\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "XZ1fmI7bD22n",
      "metadata": {
        "id": "XZ1fmI7bD22n"
      },
      "outputs": [],
      "source": [
        "class F1Score(Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        f1_score = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "        return f1_score\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_state()\n",
        "        self.recall.reset_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "qa5zc_oGFWN3",
      "metadata": {
        "id": "qa5zc_oGFWN3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "2777e5ad-d074-4ecf-babd-9f94cdaf0975"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.wrappers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-ac517de78886>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.wrappers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_validate\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Importando os módulos de cálculo de métricas\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "N_9ahB8Ch3xE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "N_9ahB8Ch3xE",
        "outputId": "9731a0ef-dabd-4431-bcd4-3125e59dc792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.975 0.002 he_normal adam\n",
            "0.975 0.002 he_normal adam\n",
            "0.975 0.002 he_normal adam\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3c0f013912e3>\u001b[0m in \u001b[0;36m<cell line: 133>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m#cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Use 5-fold cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;31m# Fit the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_safe_split\u001b[0;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mX_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mX_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_indexing.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_polars_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "import tensorflow as tf\n",
        "\n",
        "class KerasEstimator(BaseEstimator):\n",
        "    instance_counter = 0\n",
        "    def __init__(self, optimizer='adam', learning_rate=0.001, ema_momentum=0.9, kernel_initializer='he_normal'):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ema_momentum = ema_momentum\n",
        "        self.optimizer = optimizer\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        KerasEstimator.instance_counter += 1  # Initialize the counter\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = self.create_model()\n",
        "\n",
        "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='accuracy',  # Monitor the f1_score on the validation set\n",
        "            patience=10,\n",
        "            verbose=1,\n",
        "            restore_best_weights=False\n",
        "        )\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=\"/content/drive/MyDrive/AMAZON/TestesIsolados/Unet_5_pastas/\"+f'{self.optimizer}_{self.learning_rate}_{self.ema_momentum}_{self.kernel_initializer}'+'/'+f'{self.optimizer}_{self.learning_rate}_{self.ema_momentum}_{self.kernel_initializer}_+version_instance_{KerasEstimator.instance_counter}.h5',\n",
        "            monitor='accuracy',  # Monitor the f1_score on the validation set\n",
        "            verbose=1,\n",
        "            save_best_only=True,\n",
        "            mode='max'\n",
        "        )\n",
        "\n",
        "        history = self.model.fit(X, y, batch_size=2, epochs=1000, verbose=1)#callbacks=[early_stopper, checkpoint])\n",
        "        print(history.history['accuracy'])\n",
        "        with open(\"/content/drive/MyDrive/AMAZON/TestesIsolados/Unet_5_pastas/treinos1e2.txt\", \"a\") as checkpoint_file:\n",
        "          checkpoint_file.write(\"Optimizer Used: \" + self.optimizer + \"\\n\")\n",
        "          checkpoint_file.write(\"Accuracy History: \" + str(history.history['accuracy']) + \"\\n\")\n",
        "          print(\"Dados Gravados\")\n",
        "        with open(\"/content/drive/MyDrive/AMAZON/TestesIsolados/Unet_5_pastas/treinos1e2.txt\", \"a\") as checkpoint_file:\n",
        "          checkpoint_file.write(\"ema_momentum Used: \" + str(self.ema_momentum) + \"\\n\")\n",
        "          checkpoint_file.write(\"kernel_initializer: \" + str(self.kernel_initializer) + \"\\n\")\n",
        "          checkpoint_file.write(\"lr: \" + str(self.learning_rate) + \"\\n\")\n",
        "\n",
        "          print(\"Dados Gravados\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def create_model(self):\n",
        "        print(self.ema_momentum,self.learning_rate,self.kernel_initializer,self.optimizer)\n",
        "        inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "        s = tf.keras.layers.Lambda(lambda x: x / 65.536) (inputs)\n",
        "\n",
        "        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (s)\n",
        "        c1 = tf.keras.layers.Dropout(0.1) (c1)\n",
        "        c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c1)\n",
        "        p1 = tf.keras.layers.MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "        c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p1)\n",
        "        c2 = tf.keras.layers.Dropout(0.1) (c2)\n",
        "        c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c2)\n",
        "        p2 = tf.keras.layers.MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "        c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p2)\n",
        "        c3 = tf.keras.layers.Dropout(0.2) (c3)\n",
        "        c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c3)\n",
        "        p3 = tf.keras.layers.MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "        c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p3)\n",
        "        c4 = tf.keras.layers.Dropout(0.2) (c4)\n",
        "        c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c4)\n",
        "        p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "        c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (p4)\n",
        "        c5 = tf.keras.layers.Dropout(0.3) (c5)\n",
        "        c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same') (c5)\n",
        "\n",
        "        u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "        u6 = tf.keras.layers.Concatenate()([u6, c4])  # Fix the Concatenate usage\n",
        "        c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u6)\n",
        "        c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "        c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c6)\n",
        "\n",
        "        u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "        u7 = tf.keras.layers.Concatenate()([u7, c3])  # Fix the Concatenate usage\n",
        "        c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u7)\n",
        "        c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "        c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c7)\n",
        "\n",
        "        u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "        u8 = tf.keras.layers.Concatenate()([u8, c2])  # Fix the Concatenate usage\n",
        "        c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u8)\n",
        "        c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "        c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c8)\n",
        "\n",
        "\n",
        "        u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "        u9 = tf.keras.layers.Concatenate(axis=3)([u9, c1])  # Fix the Concatenate usage\n",
        "        c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(u9)\n",
        "        c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "        c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer=self.kernel_initializer, padding='same')(c9)\n",
        "\n",
        "        outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "        model = Model(inputs=[inputs], outputs=[outputs])  # Your model architecture here\n",
        "        model.compile(optimizer=self.get_optimizer(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def get_optimizer(self):\n",
        "        if self.optimizer == 'adam':\n",
        "            return tf.keras.optimizers.Adam(learning_rate=self.learning_rate, ema_momentum=self.ema_momentum)\n",
        "        elif self.optimizer == 'nadam':\n",
        "            return tf.keras.optimizers.Nadam(learning_rate=self.learning_rate, ema_momentum=self.ema_momentum)\n",
        "        elif self.optimizer == 'adamw':\n",
        "            # Implement AdamW optimizer (adjust parameters as needed)\n",
        "            return tf.keras.optimizers.AdamW(learning_rate=self.learning_rate, ema_momentum=self.ema_momentum)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown optimizer: {}\".format(self.optimizer))\n",
        "\n",
        "# Define hyperparameters for grid search\n",
        "parameters = {\n",
        "    'optimizer':['adam'], #['adam','nadam','adamw'],\n",
        "    'learning_rate': [0.002,0.003,0.004],\n",
        "    'ema_momentum': [0.975],\n",
        "    'kernel_initializer': ['he_normal']\n",
        "}\n",
        "\n",
        "# Create the wrapped KerasEstimator\n",
        "#cv = KFold(n_splits=5, shuffle=True, random_state=42)  # Use 5-fold cross-validation\n",
        "clf = GridSearchCV(estimator = KerasEstimator(), param_grid=parameters,scoring = 'f1',cv=5)\n",
        "clf.fit(X_train, Y_train)\n",
        "# Fit the grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yYQJYpJ_JEe7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "yYQJYpJ_JEe7",
        "outputId": "1e4107bb-84f3-4855-8943-e81cd8d5177b"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1583de3e21ee>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Acesse os melhores parâmetros encontrados no grid_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Melhores parâmetros encontrados: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ],
      "source": [
        "# Acesse os melhores parâmetros encontrados no grid_result\n",
        "best_params = grid_result.best_params_\n",
        "best_score = grid_result.best_score_\n",
        "\n",
        "print(\"Melhores parâmetros encontrados: \", best_params)\n",
        "print(\"Melhor precisão encontrada: \", best_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B9n3Z2DqBRyv",
      "metadata": {
        "id": "B9n3Z2DqBRyv"
      },
      "outputs": [],
      "source": [
        "modelo = 0\n",
        "model = unet()\n",
        "for train, test in cv.split(X_train,Y_train):\n",
        "    modelo=modelo+1\n",
        "    print(modelo)\n",
        "    fold_no = 1\n",
        "    acc_per_fold = []\n",
        "    filepath = \"/content/drive/MyDrive/AMAZON/TesteUnet/Unet_Adam_1e-3_10P_he_0.90_/Unet_Adam_1e-3_10P_he_0.90_\"+str(modelo)+\".h5\"\n",
        "\n",
        "    earlystopper = EarlyStopping(patience=10, verbose=1)\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1,\n",
        "                                  save_best_only=True, mode='max')\n",
        "\n",
        "    callbacks_list = [earlystopper,checkpoint]\n",
        "\n",
        "    X = X_train[train]\n",
        "    Y = Y_train[train]\n",
        "\n",
        "    Xt = X_train[test]\n",
        "    Yt = Y_train[test]\n",
        "\n",
        "    model = unet()\n",
        "    print(\"Modelo\")\n",
        "    history=0\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3,ema_momentum=0.9),\n",
        "                  metrics=[BinaryAccuracy(), F1Score()])\n",
        "\n",
        "    history = model.fit(X, Y, batch_size=8,validation_data=(Xt, Yt), epochs = 1000,\n",
        "                    callbacks=callbacks_list,shuffle=False)\n",
        "\n",
        "    plota_grafico(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nP9daxUOlYOX",
      "metadata": {
        "id": "nP9daxUOlYOX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d58afe",
      "metadata": {
        "id": "b3d58afe",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "dir = \"/content/drive/MyDrive/AMAZON/TestesIsolados/\"\n",
        "diretorio = os.listdir(dir)\n",
        "model = unet()\n",
        "todasMatrizes=[]\n",
        "print(diretorio)\n",
        "for i in range(len(diretorio)):\n",
        "  model.load_weights(dir+diretorio[i])\n",
        "  matrizes=[]\n",
        "  matrizes2=[[0,0],[0,0]]\n",
        "  amostras = 45\n",
        "  index=0\n",
        "  for _ in range(amostras):\n",
        "\n",
        "      img = cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/image/'+test_image_list[index],3)\n",
        "      img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
        "      img = img[np.newaxis, :, :, : ]\n",
        "\n",
        "      predicted_img = model.predict(img)\n",
        "      cv2.imwrite('/content/drive/MyDrive/AMAZON/Dataset/Test/'+test_image_list[index], predicted_img)\n",
        "\n",
        "      #plt.figure(figsize=(12, 12))\n",
        "      #image = cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/image/'+test_image_list[index], 2)\n",
        "      #image=image*255\n",
        "      #plt.subplot(1, 3, 1)\n",
        "      #plt.imshow(np.squeeze(image))\n",
        "      #plt.axis('off')\n",
        "      #plt.title('Original Image')\n",
        "\n",
        "      #plt.subplot(1, 3, 2)\n",
        "      #plt.imshow(np.squeeze(cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/mask/'+test_image_list[index],0)))\n",
        "      #plt.axis('off')\n",
        "      #plt.title('Original Mask')\n",
        "      list_arr = cv2.imread('/content/drive/MyDrive/AMAZON/Dataset/Test/mask/'+test_image_list[index],0).tolist()\n",
        "\n",
        "      #print(list_arr[0])\n",
        "\n",
        "\n",
        "      #plt.subplot(1, 3, 3)\n",
        "      #plt.imshow(np.squeeze(predicted_img) >= 0.5 )\n",
        "      #plt.title('Prediction')\n",
        "      #plt.axis('off')\n",
        "      predicted_img=(np.squeeze(predicted_img)>=0.5)\n",
        "\n",
        "\n",
        "      # assuming the array is named 'arr'\n",
        "      predicted_img = predicted_img.astype(np.int64)\n",
        "      list_arr2 = predicted_img.tolist()\n",
        "      #print(list_arr2[0])\n",
        "      for i in range(len(list_arr)):\n",
        "        cm = confusion_matrix(list_arr[i],list_arr2[i])\n",
        "        if cm.shape == (2, 2):\n",
        "          matrizes2[0][0]+=cm[0][0]\n",
        "          matrizes2[0][1]+=cm[0][1]\n",
        "          matrizes2[1][0]+=cm[1][0]\n",
        "          matrizes2[1][1]+=cm[1][1]\n",
        "          teste=np.cumsum(matrizes2)\n",
        "      #print(teste[3])\n",
        "      print(matrizes2[0]/teste[3],'\\n',matrizes2[1]/teste[3])\n",
        "      matrizes2=[[0,0],[0,0]]\n",
        "      matrizes.append(matrizes2)\n",
        "      plt.show()\n",
        "      index += 1\n",
        "      #print(index)\n",
        "      print(index)\n",
        "  todasMatrizes.append(matrizes)\n",
        "  print(todasMatrizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "877e3c69",
      "metadata": {
        "id": "877e3c69"
      },
      "outputs": [],
      "source": [
        "sum_confusion_matrix = np.zeros_like(matrizes[0])\n",
        "\n",
        "# iterate over all matrices and add them to the sum matrix\n",
        "for matrizes in todasMatrizes:\n",
        "  for matrix in matrizes:\n",
        "      sum_confusion_matrix += matrix\n",
        "val = sum_confusion_matrix[0][0]+sum_confusion_matrix[0][1]\n",
        "val1 = sum_confusion_matrix[1][0]+sum_confusion_matrix[1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qqVVXGzpg_T-",
      "metadata": {
        "id": "qqVVXGzpg_T-"
      },
      "outputs": [],
      "source": [
        "TP=sum_confusion_matrix[0][0]\n",
        "FP=sum_confusion_matrix[0][1]\n",
        "FN=sum_confusion_matrix[1][0]\n",
        "TN=sum_confusion_matrix[1][1]\n",
        "print(TP,FP,FN,TN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fV5xzItphC2l",
      "metadata": {
        "id": "fV5xzItphC2l"
      },
      "outputs": [],
      "source": [
        "precisao = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "F1_Score = 2 * (precisao * recall) / (precisao + recall)\n",
        "acuracia = (TP+TN) / (TN+TP+FP+FN)\n",
        "iou = TP / (TP + FP + FN)\n",
        "print(\"Precisão: \",precisao,\"\\nRecall: \",recall,\"\\nF1_Score: \",F1_Score,\"\\nAcuracia: \",acuracia,\"\\nIoU: \",iou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SpLjH0INhH2E",
      "metadata": {
        "id": "SpLjH0INhH2E"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "matriz213 =[[TP/(TP + FP),FP/(TP + FP)],[FN/(FN+TN),TN/(FN+TN)]]\n",
        "sns.heatmap(matriz213, annot=True,fmt=\".3f\", annot_kws={\"size\":12}, cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wZ1mjyqd62CT",
      "metadata": {
        "id": "wZ1mjyqd62CT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}