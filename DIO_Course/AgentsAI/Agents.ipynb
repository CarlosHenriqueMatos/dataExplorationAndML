{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d34d04-abe7-461d-95c1-b501a3c97dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a193843c-dd90-4283-b679-d05d53b9f8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response from Ollama:\n",
      ", scientific computing, data analysis, artificial intelligence, and more. Created in the late 1980s by Guido van Rossum, Python is known for its simplicity, readability, and ease of use.\n",
      "\n",
      "Here are some key features of Python:\n",
      "\n",
      " simple syntax and is relatively easy to read and write, making it a great language for beginners.\n",
      ". **High-level language**: Python abstracts away many low-level details, allowing developers to focus on the logic of their program without worrying about memory management or other low-level concerns.\n",
      "Interpreted language**: Python code is interpreted by an interpreter at runtime, rather than being compiled into machine code beforehand.\n",
      ") concepts such as classes, objects, inheritance, and polymorphism. (OOP\n",
      " library**: Python has a vast collection of built-in modules and libraries that provide a wide range of functionality for tasks such as file I/O, networking, data structures, and more.\n",
      "\n",
      " use cases for Python include:\n",
      "\n",
      " Django and Flask to build web applications.b frameworks like\n",
      " libraries like NumPy, pandas, and scikit-learn that make it easy to work with data.\n",
      " and artificial intelligence systems using libraries like TensorFlow and Keras.ning models\n",
      " Python's ease of use and flexibility make it a popular choice for automating tasks and scripting workflows.\n",
      "\n",
      " range of applications, from simple scripts to complex software systems.velopers build a wide\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "# Define the payload (your input prompt)\n",
    "payload = {\n",
    "    \"model\": \"llama3.2\",  # Replace with the model name you're using\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is Python?\"}]\n",
    "}\n",
    "\n",
    "# Send the HTTP POST request with streaming enabled\n",
    "response = requests.post(url, json=payload, stream=True)\n",
    "\n",
    "# Check the response status\n",
    "if response.status_code == 200:\n",
    "    print(\"Streaming response from Ollama:\")\n",
    "    for line in response.iter_lines(decode_unicode=True):\n",
    "        if line:  # Ignore empty lines\n",
    "            try:\n",
    "                # Parse each line as a JSON object\n",
    "                json_data = json.loads(line)\n",
    "                # Extract and print the assistant's message content\n",
    "                if \"message\" in json_data and \"content\" in json_data[\"message\"]:\n",
    "                    print(json_data[\"message\"][\"content\"], end=\"\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"\\nFailed to parse line: {line}\")\n",
    "    print()  # Ensure the final output ends with a newline\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2142083-e346-485a-a62f-6a1144a9a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response from Ollama:\n",
      " happy to share a fascinating piece of history with you.\n",
      "\n",
      " the Terracotta Army, one of the most incredible archaeological discoveries in Chinese history.\n",
      "\n",
      "The Terracotta Army: A Labor of Love and Sacrifice**\n",
      "\n",
      ", a group of farmers in Xi'an, China stumbled upon an ancient army of terracotta soldiers while digging a well. The site was initially thought to be a simple burial ground for the first emperor of China, Qin Shi Huang (259-210 BCE). However, as excavations began, it became clear that this was much more than just a tomb.\n",
      "\n",
      "otta Army is an astonishing collection of over 8,000 life-sized terracotta soldiers, each with unique facial expressions and intricate details. The army was created to protect the emperor in the afterlife and was buried alongside him as part of a massive underground complex.\n",
      "\n",
      " Huang: A Unifying Force**\n",
      "\n",
      " China, ruled from 221-210 BCE. He unified various warring states into a single empire, creating one of the largest empires in history. To secure his power and legacy, he was determined to create an army that would be unmatched in the world.\n",
      "\n",
      " Composition**\n",
      "\n",
      " Terracotta Army is divided into four divisions:\n",
      "\n",
      " majority of the army consists of infantrymen, each with a unique expression and uniform.\n",
      " Archers: These soldiers are depicted as skilled archers, carrying bows and arrows.\n",
      " Charioteers: Mounted on horseback, these soldiers represented the emperor's chariots.\n",
      " Cavalrymen: The largest and most majestic of all, these soldiers represented the emperor's personal guard.\n",
      "\n",
      "**The Construction Process**\n",
      "\n",
      " years to complete the construction of the Terracotta Army, with thousands of workers laboring under harsh conditions. The army was assembled from terracotta, a type of earthenware, and painted with detailed designs and patterns.\n",
      "\n",
      "**A Legacy of Sacrifice**\n",
      "\n",
      " of the Terracotta Army required an enormous amount of resources and human labor. Many workers lost their lives during the construction process, as documented in ancient texts. Their sacrifice allowed Qin Shi Huang to secure his legacy and create a monumental tomb that would be remembered for eternity.\n",
      "\n",
      " Terracotta Army is one of China's most famous cultural treasures, attracting millions of visitors each year. Its sheer scale, intricate details, and historical significance make it an unparalleled archaeological discovery in human history.\n",
      "\n",
      "Would you like to know more about Qin Shi Huang or ancient Chinese history?\n"
     ]
    }
   ],
   "source": [
    "# Define the payload (your input prompt)\n",
    "payload = {\n",
    "    \"model\": \"llama3.2\",  # Replace with the model name you're using\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a history\"}]\n",
    "}\n",
    "\n",
    "# Send the HTTP POST request with streaming enabled\n",
    "response = requests.post(url, json=payload, stream=True)\n",
    "\n",
    "# Check the response status\n",
    "if response.status_code == 200:\n",
    "    print(\"Streaming response from Ollama:\")\n",
    "    for line in response.iter_lines(decode_unicode=True):\n",
    "        if line:  # Ignore empty lines\n",
    "            try:\n",
    "                # Parse each line as a JSON object\n",
    "                json_data = json.loads(line)\n",
    "                # Extract and print the assistant's message content\n",
    "                if \"message\" in json_data and \"content\" in json_data[\"message\"]:\n",
    "                    print(json_data[\"message\"][\"content\"], end=\"\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"\\nFailed to parse line: {line}\")\n",
    "    print()  # Ensure the final output ends with a newline\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea30a066-b3aa-4ad4-9d65-78af29b9aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=payload, stream=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51a1bc3c-7e68-4852-838f-c14360bc2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "    response.raise_for_status()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Erro de rede: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3bcee91-5928-43d8-a4a2-582f91b37652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta do modelo:\n",
      " are so many fascinating histories to choose from, but I'll give you an overview of one of the most significant and influential ones:\n",
      "\n",
      "**The History of Ancient Egypt (3100 BCE - 30 BCE)**\n",
      "\n",
      "Ancient Egypt was one of the oldest and most advanced civilizations in human history. It emerged along the Nile River around 3100 BCE and thrived for over 3,000 years.\n",
      "\n",
      "**Early Period (3100 BCE - 2613 BCE)**\n",
      "\n",
      "The early period of Ancient Egyptian history began with the unification of Upper and Lower Egypt under King Narmer (also known as Menes). This marked the beginning of a powerful and centralized state that would shape the course of Egyptian history for centuries to come.\n",
      "\n",
      "**Old Kingdom (2613 BCE - 2181 BCE)**\n",
      "\n",
      "During the Old Kingdom, Ancient Egypt experienced a period of great stability and prosperity. The pyramids, built during this time, were some of the most impressive architectural achievements in history, with the Great Pyramid of Giza being the largest and oldest of the three.\n",
      "\n",
      "**Middle Kingdom (2040 BCE - 1750 BCE)**\n",
      "\n",
      "The Middle Kingdom was marked by a resurgence of Egyptian power and culture. During this period, the country experienced significant economic growth, military expansion, and artistic flourishing.\n",
      "\n",
      "**New Kingdom (1570 BCE - 1085 BCE)**\n",
      "\n",
      "The New Kingdom was a golden age for Ancient Egypt, with the pharaohs of this time being known as \"Living Images of Amun.\" This period saw some of the most iconic temples, tombs, and artwork from Ancient Egyptian history, including the magnificent temple at Karnak.\n",
      "\n",
      "**Decline and Fall (1085 BCE - 30 BCE)**\n",
      "\n",
      "The decline of Ancient Egypt began with internal conflicts, foreign invasions, and environmental disasters. The death of Cleopatra VII in 30 BCE marked the end of the ancient Egyptian kingdom and its legacy.\n",
      "\n",
      "**Key Figures**\n",
      "\n",
      "* **Ramses II**: A powerful pharaoh who ruled for over 60 years and left a lasting impact on Ancient Egyptian culture.\n",
      "* **Tutankhamun**: A young pharaoh whose tomb was discovered nearly intact in 1922, shedding light on the secrets of Ancient Egypt's royal tombs.\n",
      "* **Imhotep**: An architect, physician, and engineer who served as advisor to Pharaoh Djoser and designed some of Ancient Egypt's most impressive structures.\n",
      "\n",
      "**Legacy**\n",
      "\n",
      "Ancient Egyptian history has had a profound impact on modern society. The pyramids, hieroglyphics, and mummies continue to fascinate people around the world. The legacy of Ancient Egypt can be seen in everything from architecture to art, fashion, and entertainment.\n",
      "\n",
      "Would you like me to explore another historical period or topic?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL local do Ollama\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "# Payload da requisi√ß√£o\n",
    "payload = {\n",
    "    \"model\": \"llama3.2\",  # Ou \"llama3\", \"llama3:8b\", etc.\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a history\"}],\n",
    "    \"stream\": True  # Streaming ativado\n",
    "}\n",
    "\n",
    "# Cabe√ßalhos da requisi√ß√£o\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Envio da requisi√ß√£o com tratamento de erros\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "    response.raise_for_status()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Erro ao conectar √† API: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Leitura do stream linha por linha\n",
    "print(\"Resposta do modelo:\")\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        try:\n",
    "            line = line.decode(\"utf-8\")  # <-- decodifica os bytes\n",
    "            if line.startswith(\"data:\"):\n",
    "                line = line.removeprefix(\"data:\").strip()\n",
    "            json_data = json.loads(line)\n",
    "            if \"message\" in json_data and \"content\" in json_data[\"message\"]:\n",
    "                print(json_data[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "        except (json.JSONDecodeError, UnicodeDecodeError) as e:\n",
    "            print(f\"\\nErro ao processar linha: {line}\\n{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64022b2e-67fb-49f0-8ea6-2a566df9ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_codigo(codigo):\n",
    "    if \"import\" in codigo:\n",
    "        print(\"\\nüîç C√≥digo parece importar bibliotecas.\")\n",
    "    if \"for\" in codigo:\n",
    "        print(\"üîÅ Estrutura de repeti√ß√£o detectada.\")\n",
    "    if \"def\" in codigo:\n",
    "        print(\"üì¶ Fun√ß√£o detectada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106bc3f6-dc92-4979-89c1-7131d80d266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Resposta do modelo:\n",
      "C√≥digo Python para contar n√∫meros pares de 1 a 100**\n",
      "\n",
      "Aqui est√° um exemplo de c√≥digo Python que conta os n√∫meros pares de 1 a 100:\n",
      "```python\n",
      "# In√≠cio do programa\n",
      "print(\"Contando n√∫meros pares de 1 a 100\")\n",
      "\n",
      "# Loop para contar n√∫meros pares\n",
      "for i in range(2, 101, 2):\n",
      "    print(i)\n",
      "\n",
      "print(\"\\nConclus√£o: Contou\", len(range(2, 101, 2)), \"n√∫meros pares.\")\n",
      "```\n",
      "**Explica√ß√£o do c√≥digo**\n",
      "\n",
      "1. O programa come√ßa imprimindo a mensagem de introdu√ß√£o.\n",
      "2. O loop `for` √© usado para contar os n√∫meros pares de 1 a 100. A fun√ß√£o `range()` √© usada para criar um intervalo de n√∫meros, come√ßando em 2 (inclusive), terminando em 101 (mas n√£o incluindo) e saltando por 2.\n",
      "3. O incremento de 2 nos n√∫meros do loop permite que os n√∫meros pares sejam contados corretamente.\n",
      "4. Ap√≥s o loop, a mensagem \"Conclus√£o\" √© imprimida com o resultado final.\n",
      "\n",
      "**Sa√≠da do programa**\n",
      "\n",
      "Quando voc√™ executar esse c√≥digo, ele imprimir√° os n√∫meros pares de 1 a 100, como mostrado abaixo:\n",
      "```\n",
      "Contando n√∫meros pares de 1 a 100\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "...\n",
      "98\n",
      "100\n",
      "\n",
      "Conclus√£o: Contou 50 n√∫meros pares.\n",
      "```\n",
      "Essa sa√≠da √© a lista completa dos n√∫meros pares de 1 a 100, contados corretamente.üîÅ Estrutura de repeti√ß√£o detectada.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": \"llama3.2\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Escreva um c√≥digo Python que conte n√∫meros pares de 1 a 100\"}],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- Enviar requisi√ß√£o e processar resposta ---\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "    response.raise_for_status()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Erro ao conectar √† API: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"üß† Resposta do modelo:\")\n",
    "conteudo_completo = \"\"\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        try:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data:\"):\n",
    "                line = line.removeprefix(\"data:\").strip()\n",
    "            json_data = json.loads(line)\n",
    "            if \"message\" in json_data and \"content\" in json_data[\"message\"]:\n",
    "                parte = json_data[\"message\"][\"content\"]\n",
    "                print(parte, end=\"\", flush=True)\n",
    "                conteudo_completo += parte\n",
    "        except Exception as e:\n",
    "            print(f\"\\nErro ao processar linha: {line}\\n{e}\")\n",
    "\n",
    "# --- Chamar fun√ß√£o de an√°lise ap√≥s o streaming ---\n",
    "analisar_codigo(conteudo_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bbb46aa-bc9e-4836-9c62-b1371ff3d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import io\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "def executar_codigo(codigo):\n",
    "    print(\"\\n\\nüõ†Ô∏è Executando c√≥digo gerado...\\n\")\n",
    "    stdout_original = sys.stdout\n",
    "    saida = io.StringIO()\n",
    "    try:\n",
    "        with contextlib.redirect_stdout(saida):\n",
    "            exec(codigo, {})  # Executa em um namespace limpo\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao executar o c√≥digo:\\n{e}\")\n",
    "    finally:\n",
    "        sys.stdout = stdout_original\n",
    "    print(\"üì§ Sa√≠da da execu√ß√£o:\\n\" + saida.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e510e937-aa7c-4cb1-b47a-8a4f805e11d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Resposta do modelo:\n",
      " contar_numeros_pares():\n",
      "    numeros = range(1, 101)  # Cria uma lista com n√∫meros de 1 a 100\n",
      "    contagem = sum(1 for num in numeros if num % 2 == 0)  # Conta os n√∫meros pares\n",
      "    return contagem\n",
      "\n",
      "print(contar_numeros_pares())\n",
      "‚ö†Ô∏è Nenhum bloco de c√≥digo Python encontrado na resposta.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": \"llama3.2\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Escreva um c√≥digo Python que conte n√∫meros pares de 1 a 100\"}],\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- Enviar requisi√ß√£o e processar resposta ---\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, json=payload, stream=True)\n",
    "    response.raise_for_status()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Erro ao conectar √† API: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"üß† Resposta do modelo:\")\n",
    "conteudo_completo = \"\"\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        try:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data:\"):\n",
    "                line = line.removeprefix(\"data:\").strip()\n",
    "            json_data = json.loads(line)\n",
    "            if \"message\" in json_data and \"content\" in json_data[\"message\"]:\n",
    "                parte = json_data[\"message\"][\"content\"]\n",
    "                print(parte, end=\"\", flush=True)\n",
    "                conteudo_completo += parte\n",
    "        except Exception as e:\n",
    "            print(f\"\\nErro ao processar linha: {line}\\n{e}\")\n",
    "\n",
    "# --- Tentar extrair apenas o c√≥digo Python da resposta ---\n",
    "import re\n",
    "blocos = re.findall(r\"```python(.*?)```\", conteudo_completo, re.DOTALL)\n",
    "\n",
    "if blocos:\n",
    "    codigo_extraido = blocos[0].strip()\n",
    "    executar_codigo(codigo_extraido)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Nenhum bloco de c√≥digo Python encontrado na resposta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ee0363a-4d9b-47a0-a853-d44b1e163522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_prompt_modelo_ameacas(tipo_aplicacao, \n",
    "                                autenticacao, \n",
    "                                acesso_internet, \n",
    "                                dados_sensiveis, \n",
    "                                descricao_aplicacao):\n",
    "    prompt = f\"\"\"Aja como um especialista em ciberseguran√ßa com mais de 20 anos de experi√™ncia \n",
    "    utilizando a metodologia de modelagem de amea√ßas STRIDE para produzir modelos de amea√ßas \n",
    "    abrangentes para uma ampla gama de aplica√ß√µes. Sua tarefa √© analisar o resumo do c√≥digo, \n",
    "    o conte√∫do do README e a descri√ß√£o da aplica√ß√£o fornecidos para produzir uma lista de \n",
    "    amea√ßas espec√≠ficas para essa aplica√ß√£o.\n",
    "    Voce tambem √© um analista de requisitos experiente e um programador, ent√£o voc√™ ira produzir codigos e modelos de requisitos\n",
    "    Como voc√™ √© uma pessoa proativa ira gerar ap√≥s todas as sugest√µes o que voce espera como resposta, um texto corrido\n",
    "    Presta aten√ß√£o na descri√ß√£o da aplica√ß√£o e nos detalhes t√©cnicos fornecidos.\n",
    "    Exemplo de formato esperado em JSON\n",
    "\n",
    "    {{\n",
    "      \"threat_model\": [\n",
    "        {{\n",
    "          \"Threat Type\": \"Spoofing\",\n",
    "          \"Scenario\": \"Cen√°rio de exemplo 1\",\n",
    "          \"Potential Impact\": \"Impacto potencial de exemplo 1\"\n",
    "        }},\n",
    "        {{\n",
    "          \"Threat Type\": \"Spoofing\",\n",
    "          \"Scenario\": \"Cen√°rio de exemplo 2\",\n",
    "          \"Potential Impact\": \"Impacto potencial de exemplo 2\"\n",
    "        }}\n",
    "        // ... mais amea√ßas\n",
    "      ],\n",
    "      \"improvement_suggestions\": [\n",
    "        \"Por favor, forne√ßa mais detalhes sobre o fluxo de autentica√ß√£o entre os componentes para permitir uma an√°lise melhor de poss√≠veis falhas de autentica√ß√£o.\",\n",
    "        \"Considere adicionar informa√ß√µes sobre como os dados sens√≠veis s√£o armazenados e transmitidos para permitir uma an√°lise mais precisa de exposi√ß√£o de dados.\",\n",
    "        // ... mais sugest√µes para melhorar o modelo de amea√ßas\n",
    "      ]\n",
    "    }}\n",
    "    \n",
    "    Para cada uma das categorias do STRIDE (Falsifica√ß√£o de Identidade - Spoofing, \n",
    "    Viola√ß√£o de Integridade - Tampering, \n",
    "    Rep√∫dio - Repudiation, \n",
    "    Divulga√ß√£o de Informa√ß√µes - Information Disclosure, \n",
    "    Nega√ß√£o de Servi√ßo - Denial of Service, e \n",
    "    Eleva√ß√£o de Privil√©gio - Elevation of Privilege), liste m√∫ltiplas (3 ou 4) amea√ßas reais, \n",
    "    se aplic√°vel. Cada cen√°rio de amea√ßa deve apresentar uma situa√ß√£o plaus√≠vel em que a amea√ßa \n",
    "    poderia ocorrer no contexto da aplica√ß√£o.\n",
    "\n",
    "    A lista de amea√ßas deve ser apresentada em formato de tabela, \n",
    "    com as seguintes colunas:Ao fornecer o modelo de amea√ßas, utilize uma resposta formatada em JSON \n",
    "    com as chaves \"threat_model\" e \"improvement_suggestions\". Em \"threat_model\", inclua um array de \n",
    "    objetos com as chaves \"Threat Type\" (Tipo de Amea√ßa), \"Scenario\" (Cen√°rio), e \n",
    "    \"Potential Impact\" (Impacto Potencial).    \n",
    "\n",
    "    Ao fornecer o modelo de amea√ßas, utilize uma resposta formatada em JSON com as chaves \n",
    "    \"threat_model\" e \"improvement_suggestions\". \n",
    "    Em \"threat_model\", inclua um array de objetos com as chaves \"Threat Type\" (Tipo de Amea√ßa), \n",
    "    \"Scenario\" (Cen√°rio), e \"Potential Impact\" (Impacto Potencial).\n",
    "\n",
    "    Em \"improvement_suggestions\", inclua um array de strings que sugerem quais informa√ß√µes adicionais \n",
    "    poderiam ser fornecidas para tornar o modelo de amea√ßas mais completo e preciso na pr√≥xima itera√ß√£o. \n",
    "    Foque em identificar lacunas na descri√ß√£o da aplica√ß√£o que, se preenchidas, permitiriam uma \n",
    "    an√°lise mais detalhada e precisa, como por exemplo:\n",
    "    - Detalhes arquiteturais ausentes que ajudariam a identificar amea√ßas mais espec√≠ficas\n",
    "    - Fluxos de autentica√ß√£o pouco claros que precisam de mais detalhes\n",
    "    - Descri√ß√£o incompleta dos fluxos de dados\n",
    "    - Informa√ß√µes t√©cnicas da stack n√£o informadas\n",
    "    - Fronteiras ou zonas de confian√ßa do sistema n√£o especificadas\n",
    "    - Descri√ß√£o incompleta do tratamento de dados sens√≠veis\n",
    "    - Detalhes sobre\n",
    "    N√£o forne√ßa recomenda√ß√µes de seguran√ßa gen√©ricas ‚Äî foque apenas no que ajudaria a criar um\n",
    "    modelo de amea√ßas mais eficiente.\n",
    "\n",
    "    TIPO DE APLICA√á√ÉO: {tipo_aplicacao}\n",
    "    M√âTODOS DE AUTENTICA√á√ÉO: {autenticacao}\n",
    "    EXPOSTA NA INTERNET: {acesso_internet}\n",
    "    DADOS SENS√çVEIS: {dados_sensiveis}\n",
    "    RESUMO DE C√ìDIGO, CONTE√öDO DO README E DESCRI√á√ÉO DA APLICA√á√ÉO: {descricao_aplicacao}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16df49d0-0d09-413b-bdab-d172841b09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import tempfile\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from fastapi import FastAPI, UploadFile, Form, File\n",
    "from fastapi.responses import JSONResponse\n",
    "from pathlib import Path\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/chat\"\n",
    "OLLAMA_MODEL_NAME = \"llama3.2\"\n",
    "\n",
    "# Configura√ß√£o do FastAPI\n",
    "app = FastAPI()\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Permitir todas as origens\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Permitir todos os m√©todos\n",
    "    allow_headers=[\"*\"],  # Permitir todos os cabe√ßalhos\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "@app.post(\"/analisar_ameacas\")\n",
    "async def analisar_ameacas(\n",
    "    imagem: UploadFile = File(...),\n",
    "    tipo_aplicacao: str = Form(...),\n",
    "    autenticacao: str = Form(...),\n",
    "    acesso_internet: str = Form(...),\n",
    "    dados_sensiveis: str = Form(...),\n",
    "    descricao_aplicacao: str = Form(...)\n",
    "):\n",
    "    try:\n",
    "        \n",
    "        print(f\"Recebida requisi√ß√£o para analisar amea√ßas. Imagem: {imagem.filename}\")\n",
    "        # Criar o prompt para o modelo de amea√ßas (texto base)\n",
    "        prompt_text_base = criar_prompt_modelo_ameacas(tipo_aplicacao, \n",
    "                                              autenticacao, \n",
    "                                              acesso_internet, \n",
    "                                              dados_sensiveis, \n",
    "                                              descricao_aplicacao)\n",
    "        # Salvar a imagem temporariamente\n",
    "        content = await imagem.read()\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(imagem.filename).suffix) as temp_file:\n",
    "            temp_file.write(content)\n",
    "            temp_file_path = temp_file.name\n",
    "\n",
    "        # Convert imagem para base64\n",
    "        with open(temp_file_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode('ascii')\n",
    "\n",
    "        # Remover o arquivo tempor√°rio imediatamente ap√≥s a leitura\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "        # --- NOVO: Adicionar a imagem codificada ao payload do Ollama ---\n",
    "        # Ollama espera a imagem no campo 'images' da mensagem do usu√°rio\n",
    "        ollama_messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt_text_base, \"images\": [encoded_string]}\n",
    "        ]\n",
    "\n",
    "        ollama_payload = {\n",
    "            \"model\": OLLAMA_MODEL_NAME,\n",
    "            \"messages\": ollama_messages,\n",
    "            \"stream\": True # Manter streaming para processamento em tempo real se desejar\n",
    "        }\n",
    "\n",
    "        # Chamar o modelo Ollama localmente\n",
    "        # Esta √© uma chamada s√≠ncrona. Para alta performance, considere 'httpx'.\n",
    "        response = requests.post(OLLAMA_API_URL, json=ollama_payload, stream=True)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            full_response_content = \"\"\n",
    "            for line in response.iter_lines(decode_unicode=True):\n",
    "                if line: # Ignorar linhas vazias\n",
    "                    try:\n",
    "                        json_data = json.loads(line)\n",
    "                        # O Ollama envia a resposta final com 'done: true'\n",
    "                        if \"message\" in json_data and \"content\" in json_data[\"message\"]:\n",
    "                            full_response_content += json_data[\"message\"][\"content\"]\n",
    "                        # Se voc√™ quiser ver o streaming no console do servidor, descomente a linha abaixo\n",
    "                        # print(json_data.get(\"message\", {}).get(\"content\", \"\"), end=\"\")\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Falha ao parsear a linha JSON do Ollama: {line}\")\n",
    "            \n",
    "            print(\"\\nResposta completa do Ollama recebida.\") # Nova linha para o print final\n",
    "\n",
    "            # Retornar a resposta do modelo\n",
    "            # A resposta do Ollama √© apenas o texto gerado.\n",
    "            # Se voc√™ espera o formato JSON do prompt (threat_model, improvement_suggestions),\n",
    "            # o modelo LLM (ollama) precisa ser capaz de gerar JSON.\n",
    "            try:\n",
    "                # Tentar parsear a resposta como JSON\n",
    "                model_response_json = json.loads(full_response_content)\n",
    "                return JSONResponse(content=model_response_json, status_code=200)\n",
    "            except json.JSONDecodeError:\n",
    "                # Se n√£o for JSON, retornar como texto simples ou erro de formato\n",
    "                print(\"A resposta do Ollama n√£o √© um JSON v√°lido. Retornando como texto.\")\n",
    "                return JSONResponse(content={\"model_response\": full_response_content, \"warning\": \"A resposta do modelo n√£o √© um JSON v√°lido.\"}, status_code=200)\n",
    "\n",
    "        else:\n",
    "            print(f\"Erro ao chamar Ollama: {response.status_code} - {response.text}\")\n",
    "            return JSONResponse(content={\"error\": f\"Erro ao comunicar com Ollama: {response.status_code} - {response.text}\"}, status_code=500)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado: {e}\")\n",
    "        # Certifique-se de remover o arquivo tempor√°rio mesmo em caso de erro\n",
    "        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):\n",
    "            os.remove(temp_file_path)\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec68c2-30d4-4d60-99e1-61f4b9c33ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
